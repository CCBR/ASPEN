{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#aspen","title":"ASPEN","text":""},{"location":"#table-of-contents","title":"Table of Contents","text":"<ul> <li>ASPEN - **A**tac **S**eq **P**ip**E**li**N**e</li> <li>1. Outline</li> <li>2. Runtime details<ul> <li>2.1 Load Module On Biowulf</li> <li>2.2 Create Sample Manifest</li> <li>2.3 Run Pipeline</li> </ul> </li> <li>3. Genomes</li> <li>4. Disclaimer</li> <li>5. Help</li> </ul>"},{"location":"#1-outline","title":"1. Outline","text":"<p>ASPEN or **A**tac **S**eq **P**ip**E**li**N**e is CCBR's pipeline to calls peaks for ATAC-Seq datasets. It currently accepts paired-end Illumina data and calls peak using MACS2 and Genrich peak callers. Below is a brief outline of the steps performed by the pipeline:</p> <ul> <li>Trim PE reads with CutAdapt</li> <li>Remove reads aligning to known blacklisted regions, if provided</li> <li>Align reads provided genome using bowtie2. This step generates multiple output files:</li> <li><code>tagAlign.gz</code>, which is a BED6 format file mainly required for MACS2 peak calling</li> <li><code>dedup.bam</code>, deduplicated BAM format file which may be required for downstream processing (eg. TOBIAS)</li> <li><code>qsorted.bam</code>, query sorted BAM file for Genrich peak calling</li> <li>Pre-peakcalling QC metrics:</li> <li>FastQC is run pre- and post-trimming</li> <li>Fragment length distribution is calculated using custom scripts</li> <li>Preseq is run to estimate library complexity</li> <li>Post-peakcalling QC metrics:</li> <li>TSS distributions are calculated for each replicate</li> <li>FRiP (Fraction of Reads in Peaks) is calculated for each replicate</li> <li>FRiPextra calculations are performed if fripextra config files are supplied<ul> <li>Fraction of reads in DHS regions</li> <li>Fraction of reads in promoter regions</li> <li>Fraction of reads in enhancer regions</li> </ul> </li> <li>Peak calling: Peaks (NarrowPeak format) are called using MACS2 and Genrich. If multiple replicates exist per sample, consensus peaks are called (BED format).</li> <li>Peak annotation: ChIPseeker is used to annotate peaks if the genome is hg38/hg19/mm10</li> <li>Motif enrichment: Motif Enrichment is calculated using HOMER and AME (MEME suite)</li> <li>Report: MultiQC is used to generate a customized final HTML report</li> </ul>"},{"location":"#2-runtime-details","title":"2. Runtime details","text":""},{"location":"#21-load-module-on-biowulf","title":"2.1 Load module on BIOWULF","text":"<p>To clone the repo run:</p> <pre><code>% module load ccbrpipeliner\n</code></pre> <p>This will add <code>aspen</code> to your PATH environmental variable.</p> <p>NOTE: If not running on BIOWULF, please ensure that the required tools like snakemake, python and singularity are in PATH.</p>"},{"location":"#22-create-sample-manifest","title":"2.2 Create Sample Manifest","text":"<p>Once the data is stored on biowulf, sample manifest TSV (<code>samples.tsv</code>) can be created to have the following columns:</p> <ol> <li> <p>replicateName</p> </li> <li> <p>sampleName: Multiple replicates can have the same sampleName</p> </li> <li> <p>path_to_R1_fastq: absolute path is preferred</p> </li> <li> <p>path_to_R2_fastq: Required! Pipeline currently only supports paired-end data</p> </li> </ol> <p>Note that:</p> <ul> <li>symlinks are created for R1 and R2 files from the sample manifest in the results folder. These symlinks have the filenames \\&lt;replicateName&gt;.R1.fastq.gz and \\&lt;replicateName&gt;.R2.fastq.gz, respectively. Thus, original filenames do not matter and original files do not need to be renamed.</li> <li>replicateName is used as prefix for individual peak calls</li> <li>sampleName is used as prefix for consensus peak calls</li> </ul> <p>NOTE: Optionally, if running differential ATAC please also provide <code>contrasts.tsv</code> in the output folder after running <code>init</code>. This is a simple tab-delimited text file with 2 columns (Group1 and Group2) without any headers.</p>"},{"location":"#23-run-pipeline","title":"2.3 Run Pipeline","text":"<p>To get more information about how to run the pipeline simply <code>cd</code> to the above <code>CCBR_ATACseq</code> folder and run</p> <pre><code>% aspen --help\n##########################################################################################\n\nWelcome to\n____ ____ ___  ____ _  _\n|__| [__  |__] |___ |\\ |\n|  | ___] |    |___ | \\|    v1.0.0\n\nA_TAC_S_eq A_nalysis P_ip_E_li_N_e\n\n##########################################################################################\n\nThis pipeline was built by CCBR (https://bioinformatics.ccr.cancer.gov/ccbr)\nPlease contact Vishal Koparde for comments/questions (vishal.koparde@nih.gov)\n\n##########################################################################################\n\nHere is a list of genome supported by aspen:\n\n  * hg19          [Human]\n* hg38          [Human]\n* mm10          [Mouse]\n* mmul10        [Macaca mulatta(Rhesus monkey) or rheMac10]\n* bosTau9       [Bos taurus(cattle)]\n\naspen calls peaks using the following tools:\n\n * MACS2\n * Genrich        [RECOMMENDED FOR USE]\n\nUSAGE:\n  bash ./aspen -w/--workdir=&lt;WORKDIR&gt; -m/--runmode=&lt;RUNMODE&gt;\n\nRequired Arguments:\n1.  WORKDIR     : [Type: String]: Absolute or relative path to the output folder with write permissions.\n\n2.  RUNMODE     : [Type: String] Valid options:\n    * init      : initialize workdir\n    * dryrun    : dry run snakemake to generate DAG\n    * run       : run with slurm\n    * runlocal  : run without submitting to sbatch\n    ADVANCED RUNMODES (use with caution!!)\n* unlock    : unlock WORKDIR if locked by snakemake NEVER UNLOCK WORKDIR WHERE PIPELINE IS CURRENTLY RUNNING!\n    * reconfig  : recreate config file in WORKDIR (debugging option) EDITS TO config.yaml WILL BE LOST!\n    * reset     : DELETE workdir dir and re-init it (debugging option) EDITS TO ALL FILES IN WORKDIR WILL BE LOST!\n    * printbinds: print singularity binds (paths)\n* local     : same as runlocal\n\nOptional Arguments:\n\n--help|-h       : print this help\n--genome|-g     : genome eg. hg38\n--manifest|-s   : absolute path to samples.tsv. This will be copied to output folder                    (--runmode=init only)\n--useenvmod|-e  : use \"--use-enmodules\" option while running Snakemake. This is for using modules on HPC instead of containers(default).\n--singcache|-c  : singularity cache directory. Default is `/data/${USER}/.singularity` if available, or falls back to `${WORKDIR}/.singularity`.\n\n\nExample commands:\n  bash ./aspen -w=/my/output/folder -m=init\n  bash ./aspen -w=/my/output/folder -m=dryrun\n  bash ./aspen -w=/my/output/folder -m=run\n  bash ./aspen -w=/my/output/folder -m=run -c /data/${USER}/.singularity\n\n##########################################################################################\n\nVersionInfo:\n  python          : python/3.10\n  snakemake       : snakemake\n  pipeline_home   : /gpfs/gsfs10/users/CCBR_Pipeliner/Pipelines/ASPEN/dev\n  git commit/tag  : 51cb3aee2142ce1226acca97e1e662d54c881a13    v1.0.0-2-g51cb3ae\n  aspen_version   : v1.0.0\n\n##########################################################################################\n</code></pre> <p><code>aspen</code> is a Biowulf and FRCE specific wrapper script to the pipeline. Essentially, to run the pipeline the user has to follow 3 steps:</p> <ol> <li>Initialize the output folder:</li> </ol> <p>This can be done using the following command:</p> <pre><code>% aspen -m=init -w=&lt;path_to_output_folder&gt;\n</code></pre> <p>The above command will create <code>config.yaml</code> and <code>samples.tsv</code> in the output folder. Please edit these as per your requirements. You can replace the <code>samples.tsv</code> file in the output folder with the sample manifest created in the previous step outlined above. <code>contrasts.tsv</code> should also be included if running differential ATAC.</p> <ol> <li>Dryrun:</li> </ol> <p>To dry-run the pipeline, you can run the following command after initializing the output folder:</p> <pre><code>% aspen -m=dryrun -w=&lt;path_to_output_folder&gt;\n</code></pre> <p>This should list out the chain of jobs (DAG) that will be submitted to the job scheduler.</p> <ol> <li>RUN!!:</li> </ol> <p>If the dry-run looks as expected, then you can submit the job using:</p> <pre><code>% aspen -m=run -w=&lt;path_to_output_folder&gt;\n</code></pre> <p>This will submit one master job to slurm, which will in turn keep managing the entire pipeline and submit/monitor jobs to the job scheduler as and when required.</p>"},{"location":"#3-genomes","title":"3. Genomes","text":"<p>ASPEN supports the following genome versions:</p> Genome Version Organism hg38 Human hg19 Human mm10 Mouse mmul10 Macaca mulatta(Rhesus monkey) or rheMac10 bosTau9 Bos taurus(cattle)"},{"location":"#4-disclaimer","title":"4. Disclaimer","text":"<p>This snakemake pipeline is built to run on Biowulf and FRCE. But, as it uses containers for all intermediate steps, the pipeline can be executed on any HPC with minimal edits to the config file.</p>"},{"location":"#5-help","title":"5. Help","text":"<p>For comments/suggestions/advice please reach out to Vishal Koparde or CCBR_Pipeliner. You can also open a new issue here.</p> <p> Back to Top </p>"},{"location":"log/","title":"Log","text":""},{"location":"log/#creation-of-test-dataset","title":"Creation of test dataset","text":"<p>Using the D4_Meso_iCre_Dox and iCre_D0 samples from the ccbr872 mouse dataset:</p> <ul> <li>Select 2 replicates for each group .. total samples = 4</li> <li>extract readids from the chr19:10000000-20000000 region using:  <code>% samtools view /data/CCBR/projects/ccbr872/atacseq/test/bam/iCre_D0_1.dedup.bam chr19:10000000-20000000|awk -F\"\\t\" '{print $1}' |sort|uniq &gt; iCre_D0_1.chr19.readids &amp; % samtools view /data/CCBR/projects/ccbr872/atacseq/test/bam/iCre_D0_2.dedup.bam chr19:10000000-20000000|awk -F\"\\t\" '{print $1}' |sort|uniq &gt; iCre_D0_2.chr19.readids &amp; % samtools view /data/CCBR/projects/ccbr872/atacseq/test/bam/D4_Meso_iCre_Dox_1.dedup.bam chr19:10000000-20000000|awk -F\"\\t\" '{print $1}' |sort|uniq &gt; D4_Meso_iCre_Dox_1.chr19.readids &amp; % samtools view /data/CCBR/projects/ccbr872/atacseq/test/bam/D4_Meso_iCre_Dox_2.dedup.bam chr19:10000000-20000000|awk -F\"\\t\" '{print $1}' |sort|uniq &gt; D4_Meso_iCre_Dox_2.chr19.readids &amp; <pre><code> * create subsampled fastq files using these readids:\n ```\n% cd /data/CCBR/rawdata/ccbr872/ccbr872_atacseq/fastq\n% python /data/kopardevn/GitRepos/Tools/scripts/filter_fastq_by_readids_highmem_pe.py --infq iCre_D0_1.R1.fastq.gz --infq2 iCre_D0_1.R2.fastq.gz --outfq iCre_D0_1.subset.R1.fastq.gz --outfq2 iCre_D0_1.subset.R2.fastq.gz --readids iCre_D0_1.chr19.readids\n% python /data/kopardevn/GitRepos/Tools/scripts/filter_fastq_by_readids_highmem_pe.py --infq iCre_D0_2.R1.fastq.gz --infq2 iCre_D0_2.R2.fastq.gz --outfq iCre_D0_2.subset.R1.fastq.gz --outfq2 iCre_D0_2.subset.R2.fastq.gz --readids iCre_D0_2.chr19.readids\n% python /data/kopardevn/GitRepos/Tools/scripts/filter_fastq_by_readids_highmem_pe.py --infq D4_Meso_iCre_Dox_1.R1.fastq.gz --infq2 D4_Meso_iCre_Dox_1.R2.fastq.gz --outfq D4_Meso_iCre_Dox_1.subset.R1.fastq.gz --outfq2 D4_Meso_iCre_Dox_1.subset.R2.fastq.gz --readids D4_Meso_iCre_Dox_1.chr19.readids\n% python /data/kopardevn/GitRepos/Tools/scripts/filter_fastq_by_readids_highmem_pe.py --infq D4_Meso_iCre_Dox_2.R1.fastq.gz --infq2 D4_Meso_iCre_Dox_2.R2.fastq.gz --outfq D4_Meso_iCre_Dox_2.subset.R1.fastq.gz --outfq2 D4_Meso_iCre_Dox_2.subset.R2.fastq.gz --readids D4_Meso_iCre_Dox_2.chr19.readids\n ```\n\nNow, the **samples.tsv** will look something like this:\n</code></pre> sampleName  path_to_R1_fastq    path_to_R2_fastq D4_Meso_iCre_Dox_1  /data/CCBR/rawdata/ccbr872/ccbr872_atacseq/fastq/D4_Meso_iCre_Dox_1.subset.R1.fastq.paired.fq.gz    /data/CCBR/rawdata/ccbr872/ccbr872_atacseq/fastq/D4_Meso_iCre_Dox_1.subset.R2.fastq.pai red.fq.gz D4_Meso_iCre_Dox_2  /data/CCBR/rawdata/ccbr872/ccbr872_atacseq/fastq/D4_Meso_iCre_Dox_2.subset.R1.fastq.paired.fq.gz    /data/CCBR/rawdata/ccbr872/ccbr872_atacseq/fastq/D4_Meso_iCre_Dox_2.subset.R2.fastq.pai red.fq.gz iCre_D0_1   /data/CCBR/rawdata/ccbr872/ccbr872_atacseq/fastq/iCre_D0_1.subset.R1.fastq.paired.fq.gz /data/CCBR/rawdata/ccbr872/ccbr872_atacseq/fastq/iCre_D0_1.subset.R2.fastq.paired.fq.gz iCre_D0_2   /data/CCBR/rawdata/ccbr872/ccbr872_atacseq/fastq/iCre_D0_2.subset.R1.fastq.paired.fq.gz /data/CCBR/rawdata/ccbr872/ccbr872_atacseq/fastq/iCre_D0_2.subset.R2.fastq.paired.fq.gz</code></li> </ul>"}]}