{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Background \u00b6 The Assay for Transposase-Accessible Chromatin using sequencing (ATAC-seq) has revolutionized genomics by providing a rapid and sensitive method to assess chromatin accessibility across the genome. This technique offers profound insights into gene regulation, epigenetic modifications, and the dynamic landscape of the chromatin environment. To facilitate the comprehensive analysis of ATAC-seq data, the Center for Cancer Research (CCR) Collaborative Bioinformatics Resource (CCBR) has developed ASPEN ( A tac S eq P ip E li N e), an automated, robust, reproducible pipeline designed using the Snakemake pipelining framework to streamline the complexities inherent in ATAC-seq data processing.","title":"Background"},{"location":"#background","text":"The Assay for Transposase-Accessible Chromatin using sequencing (ATAC-seq) has revolutionized genomics by providing a rapid and sensitive method to assess chromatin accessibility across the genome. This technique offers profound insights into gene regulation, epigenetic modifications, and the dynamic landscape of the chromatin environment. To facilitate the comprehensive analysis of ATAC-seq data, the Center for Cancer Research (CCR) Collaborative Bioinformatics Resource (CCBR) has developed ASPEN ( A tac S eq P ip E li N e), an automated, robust, reproducible pipeline designed using the Snakemake pipelining framework to streamline the complexities inherent in ATAC-seq data processing.","title":"Background"},{"location":"changelog/","text":"ASPEN development version \u00b6 ASPEN 1.0.6 \u00b6 fix: dockername typo ( #57 , @kopardev) ASPEN 1.0.5 \u00b6 fix: ucsc tool version changed requiring newer version of GLIBC ( #54 , @kopardev) using new masterdocker v11 ASPEN 1.0.4 \u00b6 fix: DiffATAC failure ( #46 , @kopardev) fix: last line of contrasts.tsv read in correctly; black lines ignored ( #48 , @kopardev) fix: ROI calculation from fixed-width consensus peaks no longer tried to fix the peak width again ( #50 , @kopardev) feature: create diffatac results from MACS2 peaks ( #51 , @kopardev) fix: BUYINPARTITIONS fixed in wrapper for BIOWULF-only ( #52 , @kopardev) ASPEN 1.0.3 \u00b6 fix: No module named 'numpy._core._multiarray_umath' error with unset PYTHONPATH ( #43 , @kopardev) fix: jobby command points to the correct location of snakemake.log file ASPEN is now archived on Zenodo, you can cite it with the DOI 10.5281/zenodo.13755867 . ( #42 , @kelly-sovacool) ASPEN 1.0.2 \u00b6 Set the singularity cache dir if --singcache is not provided. ( #37 , @kelly-sovacool) ASPEN now has a documentation website: https://ccbr.github.io/ASPEN ASPEN 1.0.1 \u00b6 differential ATAC updated documentation updated ASPEN 1.0.0 \u00b6 completely dockerized differential ATAC ASPEN 0.6.1 \u00b6 correction to fqscreen cattle path ASPEN 0.6 \u00b6 support for mmul10 (Macaca) and bosTau9 (cattle) genomes created resource files: indexes, promoter files, tss files etc. Added Macaca and Cattle to fastqscreen indexes support increased from 4 replicate to 6 replicates macs and genrich fixed width peaks generation rule added docker updated to v10 (genome support and tidyverse added) ASPEN 0.5.3 \u00b6 Includes reference files for mmul10 ASPEN 0.5.2 \u00b6 atac_assign_multimappers.py now getting query sorted input dryrun log saved in workdir local (workdir) scriptsdir used ASPEN 0.5.1 \u00b6 typo fix in main wrapper script ASPEN 0.5 \u00b6 fastqscreen added minor bug fixes ASPEN 0.4.1 \u00b6 Bug fixes minor updates ASPEN 0.4 \u00b6 Multiqc edits README updates ASPEN 0.3 \u00b6 FRiP calculations added ASPEN 0.2 \u00b6 Peak motif enrichment with homer/meme Peak replicate/sample/peakcaller PCA comparisons after bedtools jaccard pairwise calculations ASPEN 0.1 \u00b6 first working version calls peaks with macs2/genrich annotates peaks with chipseeker (human and mouse support)","title":"Change Log"},{"location":"changelog/#aspen-development-version","text":"","title":"ASPEN development version"},{"location":"changelog/#aspen-106","text":"fix: dockername typo ( #57 , @kopardev)","title":"ASPEN 1.0.6"},{"location":"changelog/#aspen-105","text":"fix: ucsc tool version changed requiring newer version of GLIBC ( #54 , @kopardev) using new masterdocker v11","title":"ASPEN 1.0.5"},{"location":"changelog/#aspen-104","text":"fix: DiffATAC failure ( #46 , @kopardev) fix: last line of contrasts.tsv read in correctly; black lines ignored ( #48 , @kopardev) fix: ROI calculation from fixed-width consensus peaks no longer tried to fix the peak width again ( #50 , @kopardev) feature: create diffatac results from MACS2 peaks ( #51 , @kopardev) fix: BUYINPARTITIONS fixed in wrapper for BIOWULF-only ( #52 , @kopardev)","title":"ASPEN 1.0.4"},{"location":"changelog/#aspen-103","text":"fix: No module named 'numpy._core._multiarray_umath' error with unset PYTHONPATH ( #43 , @kopardev) fix: jobby command points to the correct location of snakemake.log file ASPEN is now archived on Zenodo, you can cite it with the DOI 10.5281/zenodo.13755867 . ( #42 , @kelly-sovacool)","title":"ASPEN 1.0.3"},{"location":"changelog/#aspen-102","text":"Set the singularity cache dir if --singcache is not provided. ( #37 , @kelly-sovacool) ASPEN now has a documentation website: https://ccbr.github.io/ASPEN","title":"ASPEN 1.0.2"},{"location":"changelog/#aspen-101","text":"differential ATAC updated documentation updated","title":"ASPEN 1.0.1"},{"location":"changelog/#aspen-100","text":"completely dockerized differential ATAC","title":"ASPEN 1.0.0"},{"location":"changelog/#aspen-061","text":"correction to fqscreen cattle path","title":"ASPEN 0.6.1"},{"location":"changelog/#aspen-06","text":"support for mmul10 (Macaca) and bosTau9 (cattle) genomes created resource files: indexes, promoter files, tss files etc. Added Macaca and Cattle to fastqscreen indexes support increased from 4 replicate to 6 replicates macs and genrich fixed width peaks generation rule added docker updated to v10 (genome support and tidyverse added)","title":"ASPEN 0.6"},{"location":"changelog/#aspen-053","text":"Includes reference files for mmul10","title":"ASPEN 0.5.3"},{"location":"changelog/#aspen-052","text":"atac_assign_multimappers.py now getting query sorted input dryrun log saved in workdir local (workdir) scriptsdir used","title":"ASPEN 0.5.2"},{"location":"changelog/#aspen-051","text":"typo fix in main wrapper script","title":"ASPEN 0.5.1"},{"location":"changelog/#aspen-05","text":"fastqscreen added minor bug fixes","title":"ASPEN 0.5"},{"location":"changelog/#aspen-041","text":"Bug fixes minor updates","title":"ASPEN 0.4.1"},{"location":"changelog/#aspen-04","text":"Multiqc edits README updates","title":"ASPEN 0.4"},{"location":"changelog/#aspen-03","text":"FRiP calculations added","title":"ASPEN 0.3"},{"location":"changelog/#aspen-02","text":"Peak motif enrichment with homer/meme Peak replicate/sample/peakcaller PCA comparisons after bedtools jaccard pairwise calculations","title":"ASPEN 0.2"},{"location":"changelog/#aspen-01","text":"first working version calls peaks with macs2/genrich annotates peaks with chipseeker (human and mouse support)","title":"ASPEN 0.1"},{"location":"communications/","text":"Communications About ASPEN: \u00b6 To facilitate effective interaction and support for ASPEN (ATAC-Seq PipEliNe) users, we have established the following communication channels: Feature Requests: If you have suggestions for new features or enhancements, please submit them by opening a new issue on our GitHub repository. Before doing so, we recommend reviewing the existing issues to ensure your suggestion hasn't already been addressed. Bug Reports: To report any bugs or issues encountered while using ASPEN, kindly open a new issue on our GitHub repository. Provide a detailed description of the problem, including steps to reproduce it, and attach relevant screenshots or logs to assist in diagnosing the issue. General Inquiries and Collaboration: For general questions, assistance with getting started, interpretation of results, or discussions about potential collaborations, please contact the CCBR Pipeliner team at CCBR_Pipeliner@nih.gov or reach out directly to Dr. Vishal Koparde at vishal.koparde@nih.gov . By utilizing these channels, we aim to provide prompt and effective support, fostering a collaborative environment for all ASPEN users.","title":"Communications"},{"location":"communications/#communications-about-aspen","text":"To facilitate effective interaction and support for ASPEN (ATAC-Seq PipEliNe) users, we have established the following communication channels: Feature Requests: If you have suggestions for new features or enhancements, please submit them by opening a new issue on our GitHub repository. Before doing so, we recommend reviewing the existing issues to ensure your suggestion hasn't already been addressed. Bug Reports: To report any bugs or issues encountered while using ASPEN, kindly open a new issue on our GitHub repository. Provide a detailed description of the problem, including steps to reproduce it, and attach relevant screenshots or logs to assist in diagnosing the issue. General Inquiries and Collaboration: For general questions, assistance with getting started, interpretation of results, or discussions about potential collaborations, please contact the CCBR Pipeliner team at CCBR_Pipeliner@nih.gov or reach out directly to Dr. Vishal Koparde at vishal.koparde@nih.gov . By utilizing these channels, we aim to provide prompt and effective support, fostering a collaborative environment for all ASPEN users.","title":"Communications About ASPEN:"},{"location":"contributing/","text":"Contributing to ASPEN \u00b6 Proposing changes with issues \u00b6 If you want to make a change, it's a good idea to first open an issue and make sure someone from the team agrees that it\u2019s needed. If you've decided to work on an issue, assign yourself to the issue so others will know you're working on it. Pull request process \u00b6 We use GitHub Flow as our collaboration process. Follow the steps below for detailed instructions on contributing changes to ASPEN. Clone the repo \u00b6 If you are a member of CCBR , you can clone this repository to your computer or development environment. Otherwise, you will first need to fork the repo and clone your fork. You only need to do this step once. git clone https://github.com/CCBR/ASPEN Cloning into 'ASPEN'... remote: Enumerating objects: 1136, done. remote: Counting objects: 100% (463/463), done. remote: Compressing objects: 100% (357/357), done. remote: Total 1136 (delta 149), reused 332 (delta 103), pack-reused 673 Receiving objects: 100% (1136/1136), 11.01 MiB | 9.76 MiB/s, done. Resolving deltas: 100% (530/530), done. cd ASPEN If this is your first time cloning the repo, you may need to install dependencies \u00b6 Install snakemake and singularity or docker if needed (biowulf already has these available as modules). Install the python dependencies with pip pip install . If you're developing on biowulf, you can use our shared conda environment which already has these dependencies installed . \"/data/CCBR_Pipeliner/db/PipeDB/Conda/etc/profile.d/conda.sh\" conda activate py311 Install pre-commit if you don't already have it. Then from the repo's root directory, run pre-commit install This will install the repo's pre-commit hooks. You'll only need to do this step the first time you clone the repo. Create a branch \u00b6 Create a Git branch for your pull request (PR). Give the branch a descriptive name for the changes you will make, such as iss-10 if it is for a specific issue. # create a new branch and switch to it git branch iss-10 git switch iss-10 Switched to a new branch 'iss-10' Make your changes \u00b6 Edit the code, write and run tests, and update the documentation as needed. test \u00b6 Changes to the python package code will also need unit tests to demonstrate that the changes work as intended. We write unit tests with pytest and store them in the tests/ subdirectory. Run the tests with python -m pytest . If you change the workflow , please run the workflow with the test profile and make sure your new feature or bug fix works as intended. document \u00b6 If you have added a new feature or changed the API of an existing feature, you will likely need to update the documentation in docs/ . Commit and push your changes \u00b6 If you're not sure how often you should commit or what your commits should consist of, we recommend following the \"atomic commits\" principle where each commit contains one new feature, fix, or task. Learn more about atomic commits here: https://www.freshconsulting.com/insights/blog/atomic-commits/ First, add the files that you changed to the staging area: git add path/to/changed/files/ Then make the commit. Your commit message should follow the Conventional Commits specification. Briefly, each commit should start with one of the approved types such as feat , fix , docs , etc. followed by a description of the commit. Take a look at the Conventional Commits specification for more detailed information about how to write commit messages. git commit -m 'feat: create function for awesome feature' pre-commit will enforce that your commit message and the code changes are styled correctly and will attempt to make corrections if needed. Check for added large files..............................................Passed Fix End of Files.........................................................Passed Trim Trailing Whitespace.................................................Failed hook id: trailing-whitespace exit code: 1 files were modified by this hook > Fixing path/to/changed/files/file.txt > codespell................................................................Passed style-files..........................................(no files to check)Skipped readme-rmd-rendered..................................(no files to check)Skipped use-tidy-description.................................(no files to check)Skipped In the example above, one of the hooks modified a file in the proposed commit, so the pre-commit check failed. You can run git diff to see the changes that pre-commit made and git status to see which files were modified. To proceed with the commit, re-add the modified file(s) and re-run the commit command: git add path/to/changed/files/file.txt git commit -m 'feat: create function for awesome feature' This time, all the hooks either passed or were skipped (e.g. hooks that only run on R code will not run if no R files were committed). When the pre-commit check is successful, the usual commit success message will appear after the pre-commit messages showing that the commit was created. Check for added large files..............................................Passed Fix End of Files.........................................................Passed Trim Trailing Whitespace.................................................Passed codespell................................................................Passed style-files..........................................(no files to check)Skipped readme-rmd-rendered..................................(no files to check)Skipped use-tidy-description.................................(no files to check)Skipped Conventional Commit......................................................Passed > [iss-10 9ff256e] feat: create function for awesome feature 1 file changed, 22 insertions(+), 3 deletions(-) Finally, push your changes to GitHub: git push If this is the first time you are pushing this branch, you may have to explicitly set the upstream branch: git push --set-upstream origin iss-10 Enumerating objects: 7, done. Counting objects: 100% (7/7), done. Delta compression using up to 10 threads Compressing objects: 100% (4/4), done. Writing objects: 100% (4/4), 648 bytes | 648.00 KiB/s, done. Total 4 (delta 3), reused 0 (delta 0), pack-reused 0 remote: Resolving deltas: 100% (3/3), completed with 3 local objects. remote: remote: Create a pull request for 'iss-10' on GitHub by visiting: remote: https://github.com/CCBR/ASPEN/pull/new/iss-10 remote: To https://github.com/CCBR/ASPEN > > [new branch] iss-10 -> iss-10 branch 'iss-10' set up to track 'origin/iss-10'. We recommend pushing your commits often so they will be backed up on GitHub. You can view the files in your branch on GitHub at https://github.com/CCBR/ASPEN/tree/<your-branch-name> (replace <your-branch-name> with the actual name of your branch). Create the PR \u00b6 Once your branch is ready, create a PR on GitHub: https://github.com/CCBR/ASPEN/pull/new/ Select the branch you just pushed: Edit the PR title and description. The title should briefly describe the change. Follow the comments in the template to fill out the body of the PR, and you can delete the comments (everything between <!-- and --> ) as you go. Be sure to fill out the checklist, checking off items as you complete them or striking through any irrelevant items. When you're ready, click 'Create pull request' to open it. Optionally, you can mark the PR as a draft if you're not yet ready for it to be reviewed, then change it later when you're ready. Wait for a maintainer to review your PR \u00b6 We will do our best to follow the tidyverse code review principles: https://code-review.tidyverse.org/ . The reviewer may suggest that you make changes before accepting your PR in order to improve the code quality or style. If that's the case, continue to make changes in your branch and push them to GitHub, and they will appear in the PR. Once the PR is approved, the maintainer will merge it and the issue(s) the PR links will close automatically. Congratulations and thank you for your contribution! After your PR has been merged \u00b6 After your PR has been merged, update your local clone of the repo by switching to the main branch and pulling the latest changes: git checkout main git pull It's a good idea to run git pull before creating a new branch so it will start from the most recent commits in main. Helpful links for more information \u00b6 GitHub Flow semantic versioning guidelines changelog guidelines tidyverse code review principles reproducible examples nf-core extensions for VS Code","title":"Contributing to ASPEN"},{"location":"contributing/#contributing-to-aspen","text":"","title":"Contributing to ASPEN"},{"location":"contributing/#proposing-changes-with-issues","text":"If you want to make a change, it's a good idea to first open an issue and make sure someone from the team agrees that it\u2019s needed. If you've decided to work on an issue, assign yourself to the issue so others will know you're working on it.","title":"Proposing changes with issues"},{"location":"contributing/#pull-request-process","text":"We use GitHub Flow as our collaboration process. Follow the steps below for detailed instructions on contributing changes to ASPEN.","title":"Pull request process"},{"location":"contributing/#clone-the-repo","text":"If you are a member of CCBR , you can clone this repository to your computer or development environment. Otherwise, you will first need to fork the repo and clone your fork. You only need to do this step once. git clone https://github.com/CCBR/ASPEN Cloning into 'ASPEN'... remote: Enumerating objects: 1136, done. remote: Counting objects: 100% (463/463), done. remote: Compressing objects: 100% (357/357), done. remote: Total 1136 (delta 149), reused 332 (delta 103), pack-reused 673 Receiving objects: 100% (1136/1136), 11.01 MiB | 9.76 MiB/s, done. Resolving deltas: 100% (530/530), done. cd ASPEN","title":"Clone the repo"},{"location":"contributing/#if-this-is-your-first-time-cloning-the-repo-you-may-need-to-install-dependencies","text":"Install snakemake and singularity or docker if needed (biowulf already has these available as modules). Install the python dependencies with pip pip install . If you're developing on biowulf, you can use our shared conda environment which already has these dependencies installed . \"/data/CCBR_Pipeliner/db/PipeDB/Conda/etc/profile.d/conda.sh\" conda activate py311 Install pre-commit if you don't already have it. Then from the repo's root directory, run pre-commit install This will install the repo's pre-commit hooks. You'll only need to do this step the first time you clone the repo.","title":"If this is your first time cloning the repo, you may need to install dependencies"},{"location":"contributing/#create-a-branch","text":"Create a Git branch for your pull request (PR). Give the branch a descriptive name for the changes you will make, such as iss-10 if it is for a specific issue. # create a new branch and switch to it git branch iss-10 git switch iss-10 Switched to a new branch 'iss-10'","title":"Create a branch"},{"location":"contributing/#make-your-changes","text":"Edit the code, write and run tests, and update the documentation as needed.","title":"Make your changes"},{"location":"contributing/#test","text":"Changes to the python package code will also need unit tests to demonstrate that the changes work as intended. We write unit tests with pytest and store them in the tests/ subdirectory. Run the tests with python -m pytest . If you change the workflow , please run the workflow with the test profile and make sure your new feature or bug fix works as intended.","title":"test"},{"location":"contributing/#document","text":"If you have added a new feature or changed the API of an existing feature, you will likely need to update the documentation in docs/ .","title":"document"},{"location":"contributing/#commit-and-push-your-changes","text":"If you're not sure how often you should commit or what your commits should consist of, we recommend following the \"atomic commits\" principle where each commit contains one new feature, fix, or task. Learn more about atomic commits here: https://www.freshconsulting.com/insights/blog/atomic-commits/ First, add the files that you changed to the staging area: git add path/to/changed/files/ Then make the commit. Your commit message should follow the Conventional Commits specification. Briefly, each commit should start with one of the approved types such as feat , fix , docs , etc. followed by a description of the commit. Take a look at the Conventional Commits specification for more detailed information about how to write commit messages. git commit -m 'feat: create function for awesome feature' pre-commit will enforce that your commit message and the code changes are styled correctly and will attempt to make corrections if needed. Check for added large files..............................................Passed Fix End of Files.........................................................Passed Trim Trailing Whitespace.................................................Failed hook id: trailing-whitespace exit code: 1 files were modified by this hook > Fixing path/to/changed/files/file.txt > codespell................................................................Passed style-files..........................................(no files to check)Skipped readme-rmd-rendered..................................(no files to check)Skipped use-tidy-description.................................(no files to check)Skipped In the example above, one of the hooks modified a file in the proposed commit, so the pre-commit check failed. You can run git diff to see the changes that pre-commit made and git status to see which files were modified. To proceed with the commit, re-add the modified file(s) and re-run the commit command: git add path/to/changed/files/file.txt git commit -m 'feat: create function for awesome feature' This time, all the hooks either passed or were skipped (e.g. hooks that only run on R code will not run if no R files were committed). When the pre-commit check is successful, the usual commit success message will appear after the pre-commit messages showing that the commit was created. Check for added large files..............................................Passed Fix End of Files.........................................................Passed Trim Trailing Whitespace.................................................Passed codespell................................................................Passed style-files..........................................(no files to check)Skipped readme-rmd-rendered..................................(no files to check)Skipped use-tidy-description.................................(no files to check)Skipped Conventional Commit......................................................Passed > [iss-10 9ff256e] feat: create function for awesome feature 1 file changed, 22 insertions(+), 3 deletions(-) Finally, push your changes to GitHub: git push If this is the first time you are pushing this branch, you may have to explicitly set the upstream branch: git push --set-upstream origin iss-10 Enumerating objects: 7, done. Counting objects: 100% (7/7), done. Delta compression using up to 10 threads Compressing objects: 100% (4/4), done. Writing objects: 100% (4/4), 648 bytes | 648.00 KiB/s, done. Total 4 (delta 3), reused 0 (delta 0), pack-reused 0 remote: Resolving deltas: 100% (3/3), completed with 3 local objects. remote: remote: Create a pull request for 'iss-10' on GitHub by visiting: remote: https://github.com/CCBR/ASPEN/pull/new/iss-10 remote: To https://github.com/CCBR/ASPEN > > [new branch] iss-10 -> iss-10 branch 'iss-10' set up to track 'origin/iss-10'. We recommend pushing your commits often so they will be backed up on GitHub. You can view the files in your branch on GitHub at https://github.com/CCBR/ASPEN/tree/<your-branch-name> (replace <your-branch-name> with the actual name of your branch).","title":"Commit and push your changes"},{"location":"contributing/#create-the-pr","text":"Once your branch is ready, create a PR on GitHub: https://github.com/CCBR/ASPEN/pull/new/ Select the branch you just pushed: Edit the PR title and description. The title should briefly describe the change. Follow the comments in the template to fill out the body of the PR, and you can delete the comments (everything between <!-- and --> ) as you go. Be sure to fill out the checklist, checking off items as you complete them or striking through any irrelevant items. When you're ready, click 'Create pull request' to open it. Optionally, you can mark the PR as a draft if you're not yet ready for it to be reviewed, then change it later when you're ready.","title":"Create the PR"},{"location":"contributing/#wait-for-a-maintainer-to-review-your-pr","text":"We will do our best to follow the tidyverse code review principles: https://code-review.tidyverse.org/ . The reviewer may suggest that you make changes before accepting your PR in order to improve the code quality or style. If that's the case, continue to make changes in your branch and push them to GitHub, and they will appear in the PR. Once the PR is approved, the maintainer will merge it and the issue(s) the PR links will close automatically. Congratulations and thank you for your contribution!","title":"Wait for a maintainer to review your PR"},{"location":"contributing/#after-your-pr-has-been-merged","text":"After your PR has been merged, update your local clone of the repo by switching to the main branch and pulling the latest changes: git checkout main git pull It's a good idea to run git pull before creating a new branch so it will start from the most recent commits in main.","title":"After your PR has been merged"},{"location":"contributing/#helpful-links-for-more-information","text":"GitHub Flow semantic versioning guidelines changelog guidelines tidyverse code review principles reproducible examples nf-core extensions for VS Code","title":"Helpful links for more information"},{"location":"deployment/","text":"Running ASPEN \u00b6 To effectively run the ASPEN (ATAC-Seq PipEliNe) on the Biowulf High-Performance Computing (HPC) system, please follow the detailed user guide below: Prerequisites \u00b6 Biowulf Account: Ensure you have an active Biowulf account. Data Preparation: Store your raw ATAC-Seq paired-end FASTQ files in a directory accessible from Biowulf. Setting Up the Environment \u00b6 Load the ASPEN Module on Biowulf \u00b6 To access ASPEN, load the ccbrpipeliner module: module load ccbrpipeliner/7 This command adds aspen to your system's PATH, allowing you to execute pipeline commands directly. Note : If you're operating outside of Biowulf, ensure that dependencies such as snakemake, python, and singularity are installed and accessible in your system's PATH. Create a Sample Manifest \u00b6 ASPEN requires a sample manifest file ( samples.tsv ) to identify and organize your input data. This tab-separated file should include the following columns: replicateName : Unique identifier for each replicate. sampleName : Identifier for the sample; multiple replicates can share the same sample name. path_to_R1_fastq : Absolute path to the Read 1 FASTQ file. path_to_R2_fastq : Absolute path to the Read 2 FASTQ file (required for paired-end data). Note : Symlinks for R1 and R2 files will be created in the results directory, named as .R1.fastq.gz and .R2.fastq.gz, respectively. Therefore, original filenames do not need to be altered. Note : The replicateName is used as a prefix for individual peak calls, while the sampleName serves as a prefix for consensus peak calls. Note : For differential ATAC analysis, create a contrasts.tsv file with two columns (Group1 and Group2 ... aka Sample1 and Sample2, without headers) and place it in the output directory after initialization. Ensure each group/sample in the contrast has at least two replicates, as DESeq2 requires this for accurate contrast calculations. Back to Table of Contents Running the ASPEN Pipeline \u00b6 ASPEN operates through a series of modes to facilitate various stages of the analysis. Initialize the Working Directory \u00b6 Begin by initializing your working directory, which will house configuration files and results. Replace with your desired output directory path: aspen -m = init -w = <path_to_output_folder> This command generates a config.yaml and a placeholder samples.tsv in the specified directory. Edit these files to reflect your experimental setup, replacing the placeholder samples.tsv with your prepared manifest. If performing differential analysis, include the contrasts.tsv file at this stage. Note : To explore all possible options of the aspen command you can either run it without any arguments or run aspen --help Here is what help looks like: ########################################################################################## Welcome to ____ ____ ___ ____ _ _ | __ | [ __ | __ ] | ___ | \\ | | | ___ ] | | ___ | \\| v1.0.6 A_TAC_S_eq A_nalysis P_ip_E_li_N_e ########################################################################################## This pipeline was built by CCBR ( https://bioinformatics.ccr.cancer.gov/ccbr ) Please contact Vishal Koparde for comments/questions ( vishal.koparde@nih.gov ) ########################################################################################## Here is a list of genome supported by aspen: * hg19 [ Human ] * hg38 [ Human ] * mm10 [ Mouse ] * mmul10 [ Macaca mulatta ( Rhesus monkey ) or rheMac10 ] * bosTau9 [ Bos taurus ( cattle )] aspen calls peaks using the following tools: * MACS2 * Genrich [ RECOMMENDED FOR USE ] USAGE: bash /gpfs/gsfs10/users/CCBR_Pipeliner/Pipelines/ASPEN/.v1.0.6/aspen -w/--workdir = <WORKDIR> -m/--runmode = <RUNMODE> Required Arguments: 1 . WORKDIR : [ Type: String ] : Absolute or relative path to the output folder with write permissions. 2 . RUNMODE : [ Type: String ] Valid options: * init : initialize workdir * dryrun : dry run snakemake to generate DAG * run : run with slurm * runlocal : run without submitting to sbatch ADVANCED RUNMODES ( use with caution!! ) * unlock : unlock WORKDIR if locked by snakemake NEVER UNLOCK WORKDIR WHERE PIPELINE IS CURRENTLY RUNNING! * reconfig : recreate config file in WORKDIR ( debugging option ) EDITS TO config.yaml WILL BE LOST! * reset : DELETE workdir dir and re-init it ( debugging option ) EDITS TO ALL FILES IN WORKDIR WILL BE LOST! * printbinds: print singularity binds ( paths ) * local : same as runlocal Optional Arguments: --genome | -g : genome eg. hg38 --manifest | -s : absolute path to samples.tsv. This will be copied to output folder ( --runmode = init only ) --help | -h : print this help Example commands: bash /gpfs/gsfs10/users/CCBR_Pipeliner/Pipelines/ASPEN/.v1.0.6/aspen -w = /my/output/folder -m = init bash /gpfs/gsfs10/users/CCBR_Pipeliner/Pipelines/ASPEN/.v1.0.6/aspen -w = /my/output/folder -m = dryrun bash /gpfs/gsfs10/users/CCBR_Pipeliner/Pipelines/ASPEN/.v1.0.6/aspen -w = /my/output/folder -m = run ########################################################################################## VersionInfo: python : python/3.10 snakemake : snakemake pipeline_home : /gpfs/gsfs10/users/CCBR_Pipeliner/Pipelines/ASPEN/.v1.0.6 git commit/tag : f4366158ad972bc667422dcd4783bd69fa041556 v1.0.6 aspen_version : v1.0.6 ########################################################################################## Dry Run the Pipeline \u00b6 Before executing the full analysis, perform a dry run to visualize the workflow and identify potential issues: aspen -m = dryrun -w = <path_to_output_folder> This step outlines the sequence of tasks (Directed Acyclic Graph - DAG) without actual execution, allowing you to verify the planned operations. Execute the Pipeline \u00b6 If the dry run output is satisfactory, proceed to run the pipeline: aspen -m = run -w = <path_to_output_folder> This command submits a master job to the Slurm workload manager, which orchestrates the entire analysis workflow, managing job submissions and monitoring progress. Optional Argument: --singcache or -c : Specify a Singularity cache directory. The default is /data/${USER}/.singularity if available; otherwise, it defaults to ${WORKDIR}/snakemake/.singularity . Example Command : aspen -m = run -w = /my/output/folder -c /data/ ${ USER } /.singularity This command runs the pipeline with the specified working directory and Singularity cache directory. Monitor ASPEN runs \u00b6 To monitor the status of your ASPEN pipeline and its associated jobs on a Slurm-managed system, you can utilize the squeue and scontrol commands. The squeue command provides information about jobs in the scheduling queue, while scontrol offers detailed insights into specific jobs. To view all your active and pending jobs, execute: squeue -u $USER This command lists all jobs submitted by your user account, displaying details such as job IDs, partitions, job names, user names, job states, and the nodes allocated. For more granular information about a specific job, including its child jobs spawned by ASPEN, use the scontrol command: scontrol show job <jobid> Replace with the specific Job ID of interest. This will provide comprehensive details about the job's configuration and status, aiding in effective monitoring and management of your ASPEN pipeline processes.","title":"Running ASPEN"},{"location":"deployment/#running-aspen","text":"To effectively run the ASPEN (ATAC-Seq PipEliNe) on the Biowulf High-Performance Computing (HPC) system, please follow the detailed user guide below:","title":"Running ASPEN"},{"location":"deployment/#prerequisites","text":"Biowulf Account: Ensure you have an active Biowulf account. Data Preparation: Store your raw ATAC-Seq paired-end FASTQ files in a directory accessible from Biowulf.","title":"Prerequisites"},{"location":"deployment/#setting-up-the-environment","text":"","title":"Setting Up the Environment"},{"location":"deployment/#load-the-aspen-module-on-biowulf","text":"To access ASPEN, load the ccbrpipeliner module: module load ccbrpipeliner/7 This command adds aspen to your system's PATH, allowing you to execute pipeline commands directly. Note : If you're operating outside of Biowulf, ensure that dependencies such as snakemake, python, and singularity are installed and accessible in your system's PATH.","title":"Load the ASPEN Module on Biowulf"},{"location":"deployment/#create-a-sample-manifest","text":"ASPEN requires a sample manifest file ( samples.tsv ) to identify and organize your input data. This tab-separated file should include the following columns: replicateName : Unique identifier for each replicate. sampleName : Identifier for the sample; multiple replicates can share the same sample name. path_to_R1_fastq : Absolute path to the Read 1 FASTQ file. path_to_R2_fastq : Absolute path to the Read 2 FASTQ file (required for paired-end data). Note : Symlinks for R1 and R2 files will be created in the results directory, named as .R1.fastq.gz and .R2.fastq.gz, respectively. Therefore, original filenames do not need to be altered. Note : The replicateName is used as a prefix for individual peak calls, while the sampleName serves as a prefix for consensus peak calls. Note : For differential ATAC analysis, create a contrasts.tsv file with two columns (Group1 and Group2 ... aka Sample1 and Sample2, without headers) and place it in the output directory after initialization. Ensure each group/sample in the contrast has at least two replicates, as DESeq2 requires this for accurate contrast calculations. Back to Table of Contents","title":"Create a Sample Manifest"},{"location":"deployment/#running-the-aspen-pipeline","text":"ASPEN operates through a series of modes to facilitate various stages of the analysis.","title":"Running the ASPEN Pipeline"},{"location":"deployment/#initialize-the-working-directory","text":"Begin by initializing your working directory, which will house configuration files and results. Replace with your desired output directory path: aspen -m = init -w = <path_to_output_folder> This command generates a config.yaml and a placeholder samples.tsv in the specified directory. Edit these files to reflect your experimental setup, replacing the placeholder samples.tsv with your prepared manifest. If performing differential analysis, include the contrasts.tsv file at this stage. Note : To explore all possible options of the aspen command you can either run it without any arguments or run aspen --help Here is what help looks like: ########################################################################################## Welcome to ____ ____ ___ ____ _ _ | __ | [ __ | __ ] | ___ | \\ | | | ___ ] | | ___ | \\| v1.0.6 A_TAC_S_eq A_nalysis P_ip_E_li_N_e ########################################################################################## This pipeline was built by CCBR ( https://bioinformatics.ccr.cancer.gov/ccbr ) Please contact Vishal Koparde for comments/questions ( vishal.koparde@nih.gov ) ########################################################################################## Here is a list of genome supported by aspen: * hg19 [ Human ] * hg38 [ Human ] * mm10 [ Mouse ] * mmul10 [ Macaca mulatta ( Rhesus monkey ) or rheMac10 ] * bosTau9 [ Bos taurus ( cattle )] aspen calls peaks using the following tools: * MACS2 * Genrich [ RECOMMENDED FOR USE ] USAGE: bash /gpfs/gsfs10/users/CCBR_Pipeliner/Pipelines/ASPEN/.v1.0.6/aspen -w/--workdir = <WORKDIR> -m/--runmode = <RUNMODE> Required Arguments: 1 . WORKDIR : [ Type: String ] : Absolute or relative path to the output folder with write permissions. 2 . RUNMODE : [ Type: String ] Valid options: * init : initialize workdir * dryrun : dry run snakemake to generate DAG * run : run with slurm * runlocal : run without submitting to sbatch ADVANCED RUNMODES ( use with caution!! ) * unlock : unlock WORKDIR if locked by snakemake NEVER UNLOCK WORKDIR WHERE PIPELINE IS CURRENTLY RUNNING! * reconfig : recreate config file in WORKDIR ( debugging option ) EDITS TO config.yaml WILL BE LOST! * reset : DELETE workdir dir and re-init it ( debugging option ) EDITS TO ALL FILES IN WORKDIR WILL BE LOST! * printbinds: print singularity binds ( paths ) * local : same as runlocal Optional Arguments: --genome | -g : genome eg. hg38 --manifest | -s : absolute path to samples.tsv. This will be copied to output folder ( --runmode = init only ) --help | -h : print this help Example commands: bash /gpfs/gsfs10/users/CCBR_Pipeliner/Pipelines/ASPEN/.v1.0.6/aspen -w = /my/output/folder -m = init bash /gpfs/gsfs10/users/CCBR_Pipeliner/Pipelines/ASPEN/.v1.0.6/aspen -w = /my/output/folder -m = dryrun bash /gpfs/gsfs10/users/CCBR_Pipeliner/Pipelines/ASPEN/.v1.0.6/aspen -w = /my/output/folder -m = run ########################################################################################## VersionInfo: python : python/3.10 snakemake : snakemake pipeline_home : /gpfs/gsfs10/users/CCBR_Pipeliner/Pipelines/ASPEN/.v1.0.6 git commit/tag : f4366158ad972bc667422dcd4783bd69fa041556 v1.0.6 aspen_version : v1.0.6 ##########################################################################################","title":"Initialize the Working Directory"},{"location":"deployment/#dry-run-the-pipeline","text":"Before executing the full analysis, perform a dry run to visualize the workflow and identify potential issues: aspen -m = dryrun -w = <path_to_output_folder> This step outlines the sequence of tasks (Directed Acyclic Graph - DAG) without actual execution, allowing you to verify the planned operations.","title":"Dry Run the Pipeline"},{"location":"deployment/#execute-the-pipeline","text":"If the dry run output is satisfactory, proceed to run the pipeline: aspen -m = run -w = <path_to_output_folder> This command submits a master job to the Slurm workload manager, which orchestrates the entire analysis workflow, managing job submissions and monitoring progress. Optional Argument: --singcache or -c : Specify a Singularity cache directory. The default is /data/${USER}/.singularity if available; otherwise, it defaults to ${WORKDIR}/snakemake/.singularity . Example Command : aspen -m = run -w = /my/output/folder -c /data/ ${ USER } /.singularity This command runs the pipeline with the specified working directory and Singularity cache directory.","title":"Execute the Pipeline"},{"location":"deployment/#monitor-aspen-runs","text":"To monitor the status of your ASPEN pipeline and its associated jobs on a Slurm-managed system, you can utilize the squeue and scontrol commands. The squeue command provides information about jobs in the scheduling queue, while scontrol offers detailed insights into specific jobs. To view all your active and pending jobs, execute: squeue -u $USER This command lists all jobs submitted by your user account, displaying details such as job IDs, partitions, job names, user names, job states, and the nodes allocated. For more granular information about a specific job, including its child jobs spawned by ASPEN, use the scontrol command: scontrol show job <jobid> Replace with the specific Job ID of interest. This will provide comprehensive details about the job's configuration and status, aiding in effective monitoring and management of your ASPEN pipeline processes.","title":"Monitor ASPEN runs"},{"location":"extra/","text":"Once the ROIs are established, ASPEN generates two distinct count matrices: Tn5 Nicking Sites Count Matrix : This matrix quantifies the frequency of Tn5 transposase insertion events at each ROI. The filtered.bam file (with PCR duplicates and not dedup.bam ) is used for determining Tn5 sites and counting them. The Tn5 transposase preferentially inserts into accessible regions of the chromatin, and the number of insertion events serves as a proxy for chromatin accessibility. By counting these insertion sites, researchers can accurately infer the openness of chromatin regions under different experimental conditions. Read Counts Matrix : This matrix records the number of sequencing reads mapped to each ROI. The filtered.bam file (with PCR duplicates and not dedup.bam ) is used for counting. While Tn5 nicking sites provide a more direct measure of chromatin accessibility, read counts are included in ASPEN as they have been widely used in recent publications. Analyzing both matrices together offers a comprehensive view of chromatin accessibility dynamics.","title":"Extra"},{"location":"introduction/","text":"Introduction to ATAC-seq \u00b6 ATAC-seq is a powerful technique that enables the identification of open chromatin regions, which are indicative of active regulatory elements such as promoters, enhancers, and transcription factor binding sites. By utilizing the hyperactive Tn5 transposase, ATAC-seq simultaneously fragments DNA and inserts sequencing adapters into accessible regions of the genome. This process, known as tagmentation, allows for the efficient generation of sequencing libraries from small quantities of cells, making ATAC-seq a preferred method for chromatin accessibility studies. The resulting data provide a comprehensive view of the regulatory landscape, facilitating the understanding of gene expression patterns and cellular responses to various stimuli. Containerization : To ensure reproducibility in ATAC-seq data analysis, ASPEN employs Docker containers executed via Singularity on the Biowulf system. This containerized approach encapsulates all software dependencies and environment configurations, enabling consistent and reliable analyses across different computational setups. Utilizing containerization not only streamlines the deployment process but also enhances the reproducibility of results, as the same computational environment can be replicated precisely. This methodology aligns with best practices in bioinformatics, where tools like Docker and Singularity are recommended for maintaining reproducibility in complex data analyses. Challenges in ATAC-seq Data Analysis \u00b6 Despite its advantages, ATAC-seq data analysis presents several challenges: Data Complexity : The technique generates large datasets with varying fragment sizes corresponding to nucleosome-free regions, mono-nucleosomes, and multi-nucleosomes, necessitating sophisticated computational tools for accurate interpretation. Quality Control : Ensuring high-quality data requires meticulous assessment at multiple stages, including evaluating sequencing quality, fragment size distribution, and enrichment of reads in regulatory regions. Peak Calling : Identifying regions of open chromatin (peaks) demands precise computational methods to distinguish true signals from background noise, especially in datasets with low signal-to-noise ratios. Reproducibility : Achieving consistent results across different experiments and conditions is crucial for the reliability of biological interpretations.","title":"Introduction to ATAC-seq"},{"location":"introduction/#introduction-to-atac-seq","text":"ATAC-seq is a powerful technique that enables the identification of open chromatin regions, which are indicative of active regulatory elements such as promoters, enhancers, and transcription factor binding sites. By utilizing the hyperactive Tn5 transposase, ATAC-seq simultaneously fragments DNA and inserts sequencing adapters into accessible regions of the genome. This process, known as tagmentation, allows for the efficient generation of sequencing libraries from small quantities of cells, making ATAC-seq a preferred method for chromatin accessibility studies. The resulting data provide a comprehensive view of the regulatory landscape, facilitating the understanding of gene expression patterns and cellular responses to various stimuli. Containerization : To ensure reproducibility in ATAC-seq data analysis, ASPEN employs Docker containers executed via Singularity on the Biowulf system. This containerized approach encapsulates all software dependencies and environment configurations, enabling consistent and reliable analyses across different computational setups. Utilizing containerization not only streamlines the deployment process but also enhances the reproducibility of results, as the same computational environment can be replicated precisely. This methodology aligns with best practices in bioinformatics, where tools like Docker and Singularity are recommended for maintaining reproducibility in complex data analyses.","title":"Introduction to ATAC-seq"},{"location":"introduction/#challenges-in-atac-seq-data-analysis","text":"Despite its advantages, ATAC-seq data analysis presents several challenges: Data Complexity : The technique generates large datasets with varying fragment sizes corresponding to nucleosome-free regions, mono-nucleosomes, and multi-nucleosomes, necessitating sophisticated computational tools for accurate interpretation. Quality Control : Ensuring high-quality data requires meticulous assessment at multiple stages, including evaluating sequencing quality, fragment size distribution, and enrichment of reads in regulatory regions. Peak Calling : Identifying regions of open chromatin (peaks) demands precise computational methods to distinguish true signals from background noise, especially in datasets with low signal-to-noise ratios. Reproducibility : Achieving consistent results across different experiments and conditions is crucial for the reliability of biological interpretations.","title":"Challenges in ATAC-seq Data Analysis"},{"location":"limitations/","text":"Limitations of ASPEN \u00b6 Paired-End data required : ASPEN necessitates paired-end sequencing libraries, as its current design does not support single-end data. Future updates aim to incorporate single-end data compatibility. Infrastructure limit : Designed primarily for the BIOWULF High-Performance Computing (HPC) system at the National Institutes of Health (NIH), ASPEN's configuration relies on resources specified in the config.yaml file, which are tailored to the BIOWULF file system. Adapting ASPEN for use on other HPC platforms may require adjustments, such as replicating or generating local reference data, modifying code, and accommodating different job schedulers. Plans are underway to deploy ASPEN on the Frederick Research Computing Environment (FRCE) cluster in Frederick. Footprinting analysis : While ASPEN does not perform footprinting analysis, it is compatible with the CCBR-TOBIAS pipeline, a separate tool designed for this purpose. TOBIAS (Transcription factor Occupancy prediction By Investigation of ATAC-seq Signal) analyzes ATAC-seq data to predict transcription factor occupancy but generates a substantial number of small files. ASPEN's output can serve as direct input for the CCBR_TOBIAS pipeline, facilitating integrated analyses. Genomes supported : Genomes supported is limited to: Genome Assembly Organism Scientific Name hg38 Human Homo sapiens hg19 Human Homo sapiens mm10 Mouse Mus musculus mmul10 House Mouse Mus musculus bosTau9 Domestic Cattle Bos taurus","title":"Limitations of ASPEN"},{"location":"limitations/#limitations-of-aspen","text":"Paired-End data required : ASPEN necessitates paired-end sequencing libraries, as its current design does not support single-end data. Future updates aim to incorporate single-end data compatibility. Infrastructure limit : Designed primarily for the BIOWULF High-Performance Computing (HPC) system at the National Institutes of Health (NIH), ASPEN's configuration relies on resources specified in the config.yaml file, which are tailored to the BIOWULF file system. Adapting ASPEN for use on other HPC platforms may require adjustments, such as replicating or generating local reference data, modifying code, and accommodating different job schedulers. Plans are underway to deploy ASPEN on the Frederick Research Computing Environment (FRCE) cluster in Frederick. Footprinting analysis : While ASPEN does not perform footprinting analysis, it is compatible with the CCBR-TOBIAS pipeline, a separate tool designed for this purpose. TOBIAS (Transcription factor Occupancy prediction By Investigation of ATAC-seq Signal) analyzes ATAC-seq data to predict transcription factor occupancy but generates a substantial number of small files. ASPEN's output can serve as direct input for the CCBR_TOBIAS pipeline, facilitating integrated analyses. Genomes supported : Genomes supported is limited to: Genome Assembly Organism Scientific Name hg38 Human Homo sapiens hg19 Human Homo sapiens mm10 Mouse Mus musculus mmul10 House Mouse Mus musculus bosTau9 Domestic Cattle Bos taurus","title":"Limitations of ASPEN"},{"location":"log/","text":"Creation of test dataset \u00b6 Using the D4_Meso_iCre_Dox and iCre_D0 samples from the ccbr872 mouse dataset: Select 2 replicates for each group .. total samples = 4 extract readids from the chr19:10000000-20000000 region using: % samtools view /data/CCBR/projects/ccbr872/atacseq/test/bam/iCre_D0_1.dedup.bam chr19:10000000-20000000|awk -F\"\\t\" '{print $1}' |sort|uniq > iCre_D0_1.chr19.readids & % samtools view /data/CCBR/projects/ccbr872/atacseq/test/bam/iCre_D0_2.dedup.bam chr19:10000000-20000000|awk -F\"\\t\" '{print $1}' |sort|uniq > iCre_D0_2.chr19.readids & % samtools view /data/CCBR/projects/ccbr872/atacseq/test/bam/D4_Meso_iCre_Dox_1.dedup.bam chr19:10000000-20000000|awk -F\"\\t\" '{print $1}' |sort|uniq > D4_Meso_iCre_Dox_1.chr19.readids & % samtools view /data/CCBR/projects/ccbr872/atacseq/test/bam/D4_Meso_iCre_Dox_2.dedup.bam chr19:10000000-20000000|awk -F\"\\t\" '{print $1}' |sort|uniq > D4_Meso_iCre_Dox_2.chr19.readids & * create subsampled fastq files using these readids: ``` % cd /data/CCBR/rawdata/ccbr872/ccbr872_atacseq/fastq % python /data/kopardevn/GitRepos/Tools/scripts/filter_fastq_by_readids_highmem_pe.py --infq iCre_D0_1.R1.fastq.gz --infq2 iCre_D0_1.R2.fastq.gz --outfq iCre_D0_1.subset.R1.fastq.gz --outfq2 iCre_D0_1.subset.R2.fastq.gz --readids iCre_D0_1.chr19.readids % python /data/kopardevn/GitRepos/Tools/scripts/filter_fastq_by_readids_highmem_pe.py --infq iCre_D0_2.R1.fastq.gz --infq2 iCre_D0_2.R2.fastq.gz --outfq iCre_D0_2.subset.R1.fastq.gz --outfq2 iCre_D0_2.subset.R2.fastq.gz --readids iCre_D0_2.chr19.readids % python /data/kopardevn/GitRepos/Tools/scripts/filter_fastq_by_readids_highmem_pe.py --infq D4_Meso_iCre_Dox_1.R1.fastq.gz --infq2 D4_Meso_iCre_Dox_1.R2.fastq.gz --outfq D4_Meso_iCre_Dox_1.subset.R1.fastq.gz --outfq2 D4_Meso_iCre_Dox_1.subset.R2.fastq.gz --readids D4_Meso_iCre_Dox_1.chr19.readids % python /data/kopardevn/GitRepos/Tools/scripts/filter_fastq_by_readids_highmem_pe.py --infq D4_Meso_iCre_Dox_2.R1.fastq.gz --infq2 D4_Meso_iCre_Dox_2.R2.fastq.gz --outfq D4_Meso_iCre_Dox_2.subset.R1.fastq.gz --outfq2 D4_Meso_iCre_Dox_2.subset.R2.fastq.gz --readids D4_Meso_iCre_Dox_2.chr19.readids ``` Now, the **samples.tsv** will look something like this: sampleName path_to_R1_fastq path_to_R2_fastq D4_Meso_iCre_Dox_1 /data/CCBR/rawdata/ccbr872/ccbr872_atacseq/fastq/D4_Meso_iCre_Dox_1.subset.R1.fastq.paired.fq.gz /data/CCBR/rawdata/ccbr872/ccbr872_atacseq/fastq/D4_Meso_iCre_Dox_1.subset.R2.fastq.pai red.fq.gz D4_Meso_iCre_Dox_2 /data/CCBR/rawdata/ccbr872/ccbr872_atacseq/fastq/D4_Meso_iCre_Dox_2.subset.R1.fastq.paired.fq.gz /data/CCBR/rawdata/ccbr872/ccbr872_atacseq/fastq/D4_Meso_iCre_Dox_2.subset.R2.fastq.pai red.fq.gz iCre_D0_1 /data/CCBR/rawdata/ccbr872/ccbr872_atacseq/fastq/iCre_D0_1.subset.R1.fastq.paired.fq.gz /data/CCBR/rawdata/ccbr872/ccbr872_atacseq/fastq/iCre_D0_1.subset.R2.fastq.paired.fq.gz iCre_D0_2 /data/CCBR/rawdata/ccbr872/ccbr872_atacseq/fastq/iCre_D0_2.subset.R1.fastq.paired.fq.gz /data/CCBR/rawdata/ccbr872/ccbr872_atacseq/fastq/iCre_D0_2.subset.R2.fastq.paired.fq.gz","title":"Log"},{"location":"log/#creation-of-test-dataset","text":"Using the D4_Meso_iCre_Dox and iCre_D0 samples from the ccbr872 mouse dataset: Select 2 replicates for each group .. total samples = 4 extract readids from the chr19:10000000-20000000 region using: % samtools view /data/CCBR/projects/ccbr872/atacseq/test/bam/iCre_D0_1.dedup.bam chr19:10000000-20000000|awk -F\"\\t\" '{print $1}' |sort|uniq > iCre_D0_1.chr19.readids & % samtools view /data/CCBR/projects/ccbr872/atacseq/test/bam/iCre_D0_2.dedup.bam chr19:10000000-20000000|awk -F\"\\t\" '{print $1}' |sort|uniq > iCre_D0_2.chr19.readids & % samtools view /data/CCBR/projects/ccbr872/atacseq/test/bam/D4_Meso_iCre_Dox_1.dedup.bam chr19:10000000-20000000|awk -F\"\\t\" '{print $1}' |sort|uniq > D4_Meso_iCre_Dox_1.chr19.readids & % samtools view /data/CCBR/projects/ccbr872/atacseq/test/bam/D4_Meso_iCre_Dox_2.dedup.bam chr19:10000000-20000000|awk -F\"\\t\" '{print $1}' |sort|uniq > D4_Meso_iCre_Dox_2.chr19.readids & * create subsampled fastq files using these readids: ``` % cd /data/CCBR/rawdata/ccbr872/ccbr872_atacseq/fastq % python /data/kopardevn/GitRepos/Tools/scripts/filter_fastq_by_readids_highmem_pe.py --infq iCre_D0_1.R1.fastq.gz --infq2 iCre_D0_1.R2.fastq.gz --outfq iCre_D0_1.subset.R1.fastq.gz --outfq2 iCre_D0_1.subset.R2.fastq.gz --readids iCre_D0_1.chr19.readids % python /data/kopardevn/GitRepos/Tools/scripts/filter_fastq_by_readids_highmem_pe.py --infq iCre_D0_2.R1.fastq.gz --infq2 iCre_D0_2.R2.fastq.gz --outfq iCre_D0_2.subset.R1.fastq.gz --outfq2 iCre_D0_2.subset.R2.fastq.gz --readids iCre_D0_2.chr19.readids % python /data/kopardevn/GitRepos/Tools/scripts/filter_fastq_by_readids_highmem_pe.py --infq D4_Meso_iCre_Dox_1.R1.fastq.gz --infq2 D4_Meso_iCre_Dox_1.R2.fastq.gz --outfq D4_Meso_iCre_Dox_1.subset.R1.fastq.gz --outfq2 D4_Meso_iCre_Dox_1.subset.R2.fastq.gz --readids D4_Meso_iCre_Dox_1.chr19.readids % python /data/kopardevn/GitRepos/Tools/scripts/filter_fastq_by_readids_highmem_pe.py --infq D4_Meso_iCre_Dox_2.R1.fastq.gz --infq2 D4_Meso_iCre_Dox_2.R2.fastq.gz --outfq D4_Meso_iCre_Dox_2.subset.R1.fastq.gz --outfq2 D4_Meso_iCre_Dox_2.subset.R2.fastq.gz --readids D4_Meso_iCre_Dox_2.chr19.readids ``` Now, the **samples.tsv** will look something like this: sampleName path_to_R1_fastq path_to_R2_fastq D4_Meso_iCre_Dox_1 /data/CCBR/rawdata/ccbr872/ccbr872_atacseq/fastq/D4_Meso_iCre_Dox_1.subset.R1.fastq.paired.fq.gz /data/CCBR/rawdata/ccbr872/ccbr872_atacseq/fastq/D4_Meso_iCre_Dox_1.subset.R2.fastq.pai red.fq.gz D4_Meso_iCre_Dox_2 /data/CCBR/rawdata/ccbr872/ccbr872_atacseq/fastq/D4_Meso_iCre_Dox_2.subset.R1.fastq.paired.fq.gz /data/CCBR/rawdata/ccbr872/ccbr872_atacseq/fastq/D4_Meso_iCre_Dox_2.subset.R2.fastq.pai red.fq.gz iCre_D0_1 /data/CCBR/rawdata/ccbr872/ccbr872_atacseq/fastq/iCre_D0_1.subset.R1.fastq.paired.fq.gz /data/CCBR/rawdata/ccbr872/ccbr872_atacseq/fastq/iCre_D0_1.subset.R2.fastq.paired.fq.gz iCre_D0_2 /data/CCBR/rawdata/ccbr872/ccbr872_atacseq/fastq/iCre_D0_2.subset.R1.fastq.paired.fq.gz /data/CCBR/rawdata/ccbr872/ccbr872_atacseq/fastq/iCre_D0_2.subset.R2.fastq.paired.fq.gz","title":"Creation of test dataset"},{"location":"outputs/","text":"ASPEN Outputs \u00b6 Workdir \u00b6 The workdir which is supplied as -w while running aspen init , dryrun and run commands will contain the following files: WORKDIR \u251c\u2500\u2500 cluster.json \u251c\u2500\u2500 config.yaml \u251c\u2500\u2500 contrasts.tsv \u251c\u2500\u2500 dryrun_git_commit.txt \u251c\u2500\u2500 dryrun.log \u251c\u2500\u2500 fastqs \u251c\u2500\u2500 logs \u251c\u2500\u2500 results \u251c\u2500\u2500 runinfo.yaml \u251c\u2500\u2500 sampleinfo.txt \u251c\u2500\u2500 samples.tsv \u251c\u2500\u2500 scripts \u251c\u2500\u2500 slurm-48768339.out \u251c\u2500\u2500 snakemake.log \u251c\u2500\u2500 snakemake.stats \u251c\u2500\u2500 stats \u251c\u2500\u2500 submit_script.sbatch \u2514\u2500\u2500 tools.yaml Here are more details about these files: File File Type Mode ( -m ) When This File is Created/Overwritten Description cluster.json JSON init Defines cluster resources per snakemake rule config.yaml YAML init; can be edited later Configurable parameters for this specific run contrasts.tsv TSV Needs to be added in after init List of contrasts to run, one per line; has no header dryrun_git_commit.txt TXT dryrun The git commit hash of the version of ASPEN used at dryrun dryrun.log TXT dryrun Log from -m=dryrun fastqs FOLDER dryrun Folder containing symlinks to raw data logs FOLDER dryrun Folder containing all logs including Slurm .out and .err files results FOLDER Created at dryrun but populated during run Main outputs folder runinfo.yaml YAML After completion of run Metadata about the run executor, etc. sampleinfo.txt TXT dryrun, run Tab-delimited mappings between replicateNames and sampleNames samples.tsv TSV init; can be edited later Tab-delimited manifest with replicateName , sampleName , path_to_R1_fastq , path_to_R2_fastq . This file has a header. scripts FOLDER init Folder keeps local copy of scripts called by various rules slurm-49051815.out TXT run Slurm .out file for the master job snakemake.log TXT run Snakemake .log file for the master job; older copies timestamped and moved into logs folder stats FOLDER Created at dryrun but populated during run Contains older timestamped runinfo.yaml files submit_script.sbatch TXT run Slurm script to kickstart the main Snakemake job tools.yaml YAML run YAML containing the version of tools used in the pipeline (obsolete; was used to load specific module versions prior to moving over to Docker/Singularity containers) Resultsdir \u00b6 The results directory contains the actual output files. Below are the folders that you may find within it. WORKDIR \u251c\u2500\u2500 results \u251c\u2500\u2500 dedupBam \u251c\u2500\u2500 peaks \u251c\u2500\u2500 QC \u251c\u2500\u2500 qsortedBam \u251c\u2500\u2500 tagAlign \u2514\u2500\u2500 tmp Content details: Folder Description dedupBam Deduplicated filtered BAM files; can be used for visualization. peaks Genrich/MACS2 peak calls (raw, consensus, fixed-width); also contains ROI files with Diff-ATAC results if contrasts.tsv is provided; motif enrichments using HOMER and AME; bigwigs for visualization. QC Flagstats; dupmetrics; read counts; motif enrichments; FLD stats; Fqscreen; FRiP; ChIPSeeker results; TSS enrichments; Preseq; MultiQC. qsortedBam Query name sorted BAM files; used for Genrich peak calling (includes multimappers). tagAlign tagAlign.gz files; deduplicated; used for MACS2 peak calling. tmp Can be deleted; blacklist index; intermediate FASTQs; Genrich output reads. The QC folder contains the multiqc_report.html file which provides a comprehensive summary of the quality control metrics across all samples, including read quality, duplication rates, and other relevant statistics. This report aggregates results from various QC tools such as FastQC, FastqScreen, FLD, TSS enrichment, Peak Annotations, and others, presenting them in an easy-to-read format with interactive plots and tables. It helps in quickly identifying any issues with the sequencing data and ensures that the data quality is sufficient for downstream analysis. Note: BAM files from dedupBam can be used for downstream footprinting analysis using CCBR_TOBIAS pipeline Note: bamCompare from deeptools can be run to compare BAMs from dedupBam for comprehensive BAM comparisons. Note: BAM files from dedupBam can also be converted to BED format and processed with chromVAR to identify variability in motif accessibility across samples and assess differentially active transcription factors from the JASPAR database. Most of the above folders are self-explanatory. The peaks folder has this hierarchy: WORKDIR \u251c\u2500\u2500 results \u251c\u2500\u2500 peaks \u251c\u2500\u2500 genrich \u2502 \u251c\u2500\u2500 <replicateName>.genrich.narrowPeak \u2502 \u251c\u2500\u2500 <replicateName>.genrich.narrowPeak.annotated \u2502 \u251c\u2500\u2500 <replicateName>.genrich.narrowPeak.genelist \u2502 \u251c\u2500\u2500 <replicateName>.genrich.narrowPeak.annotation_summary \u2502 \u251c\u2500\u2500 <replicateName>.genrich.narrowPeak.annotation_distribution \u2502 \u251c\u2500\u2500 <sampleName>.genrich.pooled.narrowPeak \u2502 \u251c\u2500\u2500 <sampleName>.genrich.consensus.bed \u2502 \u251c\u2500\u2500 ROI.counts.tsv \u2502 \u251c\u2500\u2500 bigwig \u2502 \u251c\u2500\u2500 <replicateName>.genrich.narrowPeak_motif_enrichment \u2502 \u2502 \u2514\u2500\u2500 knownResults \u2502 \u251c\u2500\u2500 DiffATAC \u2502 \u251c\u2500\u2500 <replicateName>.genrich.consensus.bed_motif_enrichment \u2502 \u2514\u2500\u2500 tn5nicks \u2514\u2500\u2500 macs2 \u2502 \u251c\u2500\u2500 <replicateName>.macs2.narrowPeak \u2502 \u251c\u2500\u2500 <replicateName>.macs2.narrowPeak.annotated \u2502 \u251c\u2500\u2500 <replicateName>.macs2.narrowPeak.genelist \u2502 \u251c\u2500\u2500 <replicateName>.macs2.narrowPeak.annotation_summary \u2502 \u251c\u2500\u2500 <replicateName>.macs2.narrowPeak.annotation_distribution \u2502 \u251c\u2500\u2500 <sampleName>.macs2.pooled.narrowPeak \u2502 \u251c\u2500\u2500 <sampleName>.macs2.consensus.bed \u2502 \u251c\u2500\u2500 ROI.counts.tsv \u251c\u2500\u2500 bigwig \u251c\u2500\u2500 <replicateName>.macs2.narrowPeak_motif_enrichment \u2502 \u2514\u2500\u2500 knownResults \u251c\u2500\u2500 DiffATAC \u2502 \u251c\u2500\u2500 <replicateName>.macs2.consensus.bed_motif_enrichment \u251c\u2500\u2500 fixed_width \u2514\u2500\u2500 tn5nicks Some of the important folders and files are highlighted below: Folders \u00b6 bigwig : For easy visualization, they are converted to bigWig format and saved in respective bigwig folders. The bigWig files can be directly loaded into UCSC Browser or IGV . tn5nicks : This folder host the per-replicate BAM files containing the Tn5 nicking sites in Genrich or MACS2 \"peakcalling\" reads, respectively. DiffATAC : Contains the DESeq2 differential accessiblity results, both per-contrast and aggregated accross all contrasts in contrasts.tsv . These results are solely based on tn5 nick counts. fixed_width : This folder contains fixed-width consensus peaks across replicates and samples, represented in the \"Regions-Of-Interest\" files. The ROI.bed file lists genomic regions where chromatin accessibility is analyzed using DESeq2, with results stored in the DiffATAC folder. <replicateName>.macs2.narrowPeak_motif_enrichment ; <replicateName>.genrich.narrowPeak_motif_enrichment ; <replicateName>.macs2.consensus.bed_motif_enrichment ; <replicateName>.genrich.consensus.bed_motif_enrichment : Contains the motif enrichments calculated using HOMER and AME for peaks called for each replicate, sample consensus peaks using both MACS2 and Genrich. Specifically, two types of motif enrichments are performed: Enrichment of known HOCOMOCO (version 11) motifs for HUMAN or MOUSE or BOTH using HOMER . See file knownResults.html . de novo motif enrichment using AME from MEME suite. See file ame_results.txt . Custom parallelization is used to optimize AME based enrichment analysis. Files \u00b6 *.narrowPeak : Called peaks from Genrich or MACS2 Annotated peak files: Peaks are annotated with ChIPSeeker and results are saved in the following files: .annotated Tab-delimited txt file with the following columns: Column Number Field Name Description 1 #peakID Peak identifier 2 chrom Peak chromosome 3 chromStart Peak start coordinate 4 chromEnd Peak end coordinate 5 width Peak width 6 annotation Peak annotation (Promoter; 3' or 5' UTR; Distal; Downstream; Exon; Intron) 7 geneChr Gene chromosome 8 geneStart Gene start coordinate 9 geneEnd Gene end coordinate 10 geneLength Gene length (including introns) 11 geneStrand Gene strand 12 geneId Gene identifier 13 transcriptId Transcript identifier 14 distanceToTSS Distance of peak from the Transcription Start Site 15 ENSEMBL Gene Ensembl ID 16 SYMBOL Gene symbol 17 GENENAME Gene description 18 score Score from .narrowPeak file 19 signalValue Signal from .narrowPeak file 20 pValue p-value from .narrowPeak file 21 qValue q-value from .narrowPeak file 22 peak Distance of peak summit from peak start coordinate .genelist This is a tab-delimited file with names (Ensembl ID, gene symbol) of genes which have ATAC-seq peaks in their promotor regions. This file can be used downstream for gene enrichment analysis (ORA or over-representation analysis). .annotation_summary ; .annotation_distribution Tab-delimited files that provide statistics on peak annotations, quantifying the number of peaks found in Promoters, Exonic regions, Distal Intergenic regions, etc. The .annotation_distribution is use to create visualization of these annotation-distributions in the MultiQC report. ROI.counts.tsv This file contains the read counts for each Region-Of-Interest (ROI) across all replicates of all samples. It is a tab-delimited file with the following columns: Column Number Field Name Description 1 Geneid Region-Of-Interest identifier 2 Chr Chromosome of the ROI 3 Start Start coordinate of the ROI 4 End End coordinate of the ROI 5 Strand \".\" 6 Length Length of the ROI 7 sample1_replicate1 Tn5 nicking site counts in this ROI for replicate1 of sample1 8 sample1_replicate2 Tn5 nicking site counts in this ROI for replicate2 of sample1 ... ... ... n sampleN_replicateM Tn5 nicking site counts in this ROI for replicateM of sampleN Each row represents a specific ROI, and the columns contain the read counts for each sample, allowing for differential accessibility analysis. DISCLAIMER: This folder hierarchy is specific to v1.0.6 and is subject to change with version.","title":"ASPEN Output"},{"location":"outputs/#aspen-outputs","text":"","title":"ASPEN Outputs"},{"location":"outputs/#workdir","text":"The workdir which is supplied as -w while running aspen init , dryrun and run commands will contain the following files: WORKDIR \u251c\u2500\u2500 cluster.json \u251c\u2500\u2500 config.yaml \u251c\u2500\u2500 contrasts.tsv \u251c\u2500\u2500 dryrun_git_commit.txt \u251c\u2500\u2500 dryrun.log \u251c\u2500\u2500 fastqs \u251c\u2500\u2500 logs \u251c\u2500\u2500 results \u251c\u2500\u2500 runinfo.yaml \u251c\u2500\u2500 sampleinfo.txt \u251c\u2500\u2500 samples.tsv \u251c\u2500\u2500 scripts \u251c\u2500\u2500 slurm-48768339.out \u251c\u2500\u2500 snakemake.log \u251c\u2500\u2500 snakemake.stats \u251c\u2500\u2500 stats \u251c\u2500\u2500 submit_script.sbatch \u2514\u2500\u2500 tools.yaml Here are more details about these files: File File Type Mode ( -m ) When This File is Created/Overwritten Description cluster.json JSON init Defines cluster resources per snakemake rule config.yaml YAML init; can be edited later Configurable parameters for this specific run contrasts.tsv TSV Needs to be added in after init List of contrasts to run, one per line; has no header dryrun_git_commit.txt TXT dryrun The git commit hash of the version of ASPEN used at dryrun dryrun.log TXT dryrun Log from -m=dryrun fastqs FOLDER dryrun Folder containing symlinks to raw data logs FOLDER dryrun Folder containing all logs including Slurm .out and .err files results FOLDER Created at dryrun but populated during run Main outputs folder runinfo.yaml YAML After completion of run Metadata about the run executor, etc. sampleinfo.txt TXT dryrun, run Tab-delimited mappings between replicateNames and sampleNames samples.tsv TSV init; can be edited later Tab-delimited manifest with replicateName , sampleName , path_to_R1_fastq , path_to_R2_fastq . This file has a header. scripts FOLDER init Folder keeps local copy of scripts called by various rules slurm-49051815.out TXT run Slurm .out file for the master job snakemake.log TXT run Snakemake .log file for the master job; older copies timestamped and moved into logs folder stats FOLDER Created at dryrun but populated during run Contains older timestamped runinfo.yaml files submit_script.sbatch TXT run Slurm script to kickstart the main Snakemake job tools.yaml YAML run YAML containing the version of tools used in the pipeline (obsolete; was used to load specific module versions prior to moving over to Docker/Singularity containers)","title":"Workdir"},{"location":"outputs/#resultsdir","text":"The results directory contains the actual output files. Below are the folders that you may find within it. WORKDIR \u251c\u2500\u2500 results \u251c\u2500\u2500 dedupBam \u251c\u2500\u2500 peaks \u251c\u2500\u2500 QC \u251c\u2500\u2500 qsortedBam \u251c\u2500\u2500 tagAlign \u2514\u2500\u2500 tmp Content details: Folder Description dedupBam Deduplicated filtered BAM files; can be used for visualization. peaks Genrich/MACS2 peak calls (raw, consensus, fixed-width); also contains ROI files with Diff-ATAC results if contrasts.tsv is provided; motif enrichments using HOMER and AME; bigwigs for visualization. QC Flagstats; dupmetrics; read counts; motif enrichments; FLD stats; Fqscreen; FRiP; ChIPSeeker results; TSS enrichments; Preseq; MultiQC. qsortedBam Query name sorted BAM files; used for Genrich peak calling (includes multimappers). tagAlign tagAlign.gz files; deduplicated; used for MACS2 peak calling. tmp Can be deleted; blacklist index; intermediate FASTQs; Genrich output reads. The QC folder contains the multiqc_report.html file which provides a comprehensive summary of the quality control metrics across all samples, including read quality, duplication rates, and other relevant statistics. This report aggregates results from various QC tools such as FastQC, FastqScreen, FLD, TSS enrichment, Peak Annotations, and others, presenting them in an easy-to-read format with interactive plots and tables. It helps in quickly identifying any issues with the sequencing data and ensures that the data quality is sufficient for downstream analysis. Note: BAM files from dedupBam can be used for downstream footprinting analysis using CCBR_TOBIAS pipeline Note: bamCompare from deeptools can be run to compare BAMs from dedupBam for comprehensive BAM comparisons. Note: BAM files from dedupBam can also be converted to BED format and processed with chromVAR to identify variability in motif accessibility across samples and assess differentially active transcription factors from the JASPAR database. Most of the above folders are self-explanatory. The peaks folder has this hierarchy: WORKDIR \u251c\u2500\u2500 results \u251c\u2500\u2500 peaks \u251c\u2500\u2500 genrich \u2502 \u251c\u2500\u2500 <replicateName>.genrich.narrowPeak \u2502 \u251c\u2500\u2500 <replicateName>.genrich.narrowPeak.annotated \u2502 \u251c\u2500\u2500 <replicateName>.genrich.narrowPeak.genelist \u2502 \u251c\u2500\u2500 <replicateName>.genrich.narrowPeak.annotation_summary \u2502 \u251c\u2500\u2500 <replicateName>.genrich.narrowPeak.annotation_distribution \u2502 \u251c\u2500\u2500 <sampleName>.genrich.pooled.narrowPeak \u2502 \u251c\u2500\u2500 <sampleName>.genrich.consensus.bed \u2502 \u251c\u2500\u2500 ROI.counts.tsv \u2502 \u251c\u2500\u2500 bigwig \u2502 \u251c\u2500\u2500 <replicateName>.genrich.narrowPeak_motif_enrichment \u2502 \u2502 \u2514\u2500\u2500 knownResults \u2502 \u251c\u2500\u2500 DiffATAC \u2502 \u251c\u2500\u2500 <replicateName>.genrich.consensus.bed_motif_enrichment \u2502 \u2514\u2500\u2500 tn5nicks \u2514\u2500\u2500 macs2 \u2502 \u251c\u2500\u2500 <replicateName>.macs2.narrowPeak \u2502 \u251c\u2500\u2500 <replicateName>.macs2.narrowPeak.annotated \u2502 \u251c\u2500\u2500 <replicateName>.macs2.narrowPeak.genelist \u2502 \u251c\u2500\u2500 <replicateName>.macs2.narrowPeak.annotation_summary \u2502 \u251c\u2500\u2500 <replicateName>.macs2.narrowPeak.annotation_distribution \u2502 \u251c\u2500\u2500 <sampleName>.macs2.pooled.narrowPeak \u2502 \u251c\u2500\u2500 <sampleName>.macs2.consensus.bed \u2502 \u251c\u2500\u2500 ROI.counts.tsv \u251c\u2500\u2500 bigwig \u251c\u2500\u2500 <replicateName>.macs2.narrowPeak_motif_enrichment \u2502 \u2514\u2500\u2500 knownResults \u251c\u2500\u2500 DiffATAC \u2502 \u251c\u2500\u2500 <replicateName>.macs2.consensus.bed_motif_enrichment \u251c\u2500\u2500 fixed_width \u2514\u2500\u2500 tn5nicks Some of the important folders and files are highlighted below:","title":"Resultsdir"},{"location":"outputs/#folders","text":"bigwig : For easy visualization, they are converted to bigWig format and saved in respective bigwig folders. The bigWig files can be directly loaded into UCSC Browser or IGV . tn5nicks : This folder host the per-replicate BAM files containing the Tn5 nicking sites in Genrich or MACS2 \"peakcalling\" reads, respectively. DiffATAC : Contains the DESeq2 differential accessiblity results, both per-contrast and aggregated accross all contrasts in contrasts.tsv . These results are solely based on tn5 nick counts. fixed_width : This folder contains fixed-width consensus peaks across replicates and samples, represented in the \"Regions-Of-Interest\" files. The ROI.bed file lists genomic regions where chromatin accessibility is analyzed using DESeq2, with results stored in the DiffATAC folder. <replicateName>.macs2.narrowPeak_motif_enrichment ; <replicateName>.genrich.narrowPeak_motif_enrichment ; <replicateName>.macs2.consensus.bed_motif_enrichment ; <replicateName>.genrich.consensus.bed_motif_enrichment : Contains the motif enrichments calculated using HOMER and AME for peaks called for each replicate, sample consensus peaks using both MACS2 and Genrich. Specifically, two types of motif enrichments are performed: Enrichment of known HOCOMOCO (version 11) motifs for HUMAN or MOUSE or BOTH using HOMER . See file knownResults.html . de novo motif enrichment using AME from MEME suite. See file ame_results.txt . Custom parallelization is used to optimize AME based enrichment analysis.","title":"Folders"},{"location":"outputs/#files","text":"*.narrowPeak : Called peaks from Genrich or MACS2 Annotated peak files: Peaks are annotated with ChIPSeeker and results are saved in the following files: .annotated Tab-delimited txt file with the following columns: Column Number Field Name Description 1 #peakID Peak identifier 2 chrom Peak chromosome 3 chromStart Peak start coordinate 4 chromEnd Peak end coordinate 5 width Peak width 6 annotation Peak annotation (Promoter; 3' or 5' UTR; Distal; Downstream; Exon; Intron) 7 geneChr Gene chromosome 8 geneStart Gene start coordinate 9 geneEnd Gene end coordinate 10 geneLength Gene length (including introns) 11 geneStrand Gene strand 12 geneId Gene identifier 13 transcriptId Transcript identifier 14 distanceToTSS Distance of peak from the Transcription Start Site 15 ENSEMBL Gene Ensembl ID 16 SYMBOL Gene symbol 17 GENENAME Gene description 18 score Score from .narrowPeak file 19 signalValue Signal from .narrowPeak file 20 pValue p-value from .narrowPeak file 21 qValue q-value from .narrowPeak file 22 peak Distance of peak summit from peak start coordinate .genelist This is a tab-delimited file with names (Ensembl ID, gene symbol) of genes which have ATAC-seq peaks in their promotor regions. This file can be used downstream for gene enrichment analysis (ORA or over-representation analysis). .annotation_summary ; .annotation_distribution Tab-delimited files that provide statistics on peak annotations, quantifying the number of peaks found in Promoters, Exonic regions, Distal Intergenic regions, etc. The .annotation_distribution is use to create visualization of these annotation-distributions in the MultiQC report. ROI.counts.tsv This file contains the read counts for each Region-Of-Interest (ROI) across all replicates of all samples. It is a tab-delimited file with the following columns: Column Number Field Name Description 1 Geneid Region-Of-Interest identifier 2 Chr Chromosome of the ROI 3 Start Start coordinate of the ROI 4 End End coordinate of the ROI 5 Strand \".\" 6 Length Length of the ROI 7 sample1_replicate1 Tn5 nicking site counts in this ROI for replicate1 of sample1 8 sample1_replicate2 Tn5 nicking site counts in this ROI for replicate2 of sample1 ... ... ... n sampleN_replicateM Tn5 nicking site counts in this ROI for replicateM of sampleN Each row represents a specific ROI, and the columns contain the read counts for each sample, allowing for differential accessibility analysis. DISCLAIMER: This folder hierarchy is specific to v1.0.6 and is subject to change with version.","title":"Files"},{"location":"overview/","text":"Overview of ASPEN \u00b6 To address these challenges, CCBR developed ASPEN ( A tac S eq P ip E li N e), an automated pipeline tailored for the comprehensive analysis of ATAC-seq data. ASPEN is designed to process paired-end Illumina sequencing data, guiding users from raw data through quality control, alignment, peak calling, and downstream analyses. By integrating a suite of established bioinformatics tools and adhering to best practices, ASPEN ensures robust, reproducible, and high-quality results. For more information on the challenges in ATAC-seq data analysis, refer to the [Challenges in ATAC-seq Data Analysis] section. Data Preprocessing \u00b6 Adapter Trimming \u00b6 Utilizes CutAdapt to remove adapter sequences from raw reads, ensuring that subsequent analyses are not confounded by extraneous sequences. Quality Assessment \u00b6 Employs FastQC for initial quality checks and MultiQC for aggregated reporting, providing comprehensive insights into data quality and highlighting potential issues such as low-quality bases or GC content biases. Alignment and Filtering \u00b6 Blacklist Filtering \u00b6 Removes reads aligning to known blacklisted regions and mitochondria, reducing potential biases in peak detection and ensuring that analyses focus on biologically relevant regions. Read Alignment \u00b6 Aligns reads to the reference genome using Bowtie2, generating multiple output files, including qsorted.bam / tagAlign.gz for peak calling and dedup.bam for downstream analyses. Peak Calling and Annotation \u00b6 Peak Detection \u00b6 Implements MACS2 and Genrich to identify regions of open chromatin, accommodating both narrow and broad peak detection to capture a wide range of regulatory elements. Default MACS2 are selected from ENCODE. Peak calling uses lenient q-value setting and a q-value filter is then applied on the .narrowPeak file. Consensus Peaks \u00b6 For datasets with multiple replicates, ASPEN generates consensus peak sets based on simple overlaps between replicates and keeping peaks represented in >= 50% of replicates. Thus enhancing the reliability and reproducibility of detected regions by focusing on peaks consistently observed across replicates. Peak Annotation \u00b6 Utilizes ChIPseeker to annotate peaks, providing context regarding their genomic locations and potential regulatory roles, such as associations with promoters, enhancers, or gene bodies. Quality Control Metrics \u00b6 Fragment Length Distribution \u00b6 Custom scripts are utilized to analyze insert size to assess nucleosome positioning and sample quality, with characteristic patterns indicating the presence of nucleosome-free regions and mono- or di-nucleosomes. Library Complexity \u00b6 Estimates complexity using Preseq, aiding in the evaluation of sequencing depth sufficiency and potential PCR biases. Transcription Start Site (TSS) Enrichment \u00b6 Calculates TSS enrichment scores, serving as indicators of data quality by measuring the accumulation of reads around transcription start sites, a hallmark of open chromatin. Fraction of Reads in Peaks (FRiP) \u00b6 Determines the proportion of reads within called peaks, reflecting the signal-to-noise ratio and overall quality of the dataset. Fractions if reads in Promoters, Enhancers and DHS (DNase Hyper Sensitivity) regions are also computed. Motif Enrichment Analysis \u00b6 HOMER and AME \u00b6 Conducts motif enrichment analyses to identify potential transcription factor binding sites within accessible regions, offering insights into regulatory mechanisms and facilitating the discovery of key drivers of gene expression. Comprehensive Reporting \u00b6 MultiQC Integration \u00b6 Generates an extensive HTML report consolidating all QC metrics and analysis results, facilitating easy interpretation, visualization, and sharing of findings. Differential Accessiblity Analyses \u00b6 In addition to its core functionalities, ASPEN offers advanced capabilities for differential accessibility analysis, enabling researchers to identify and interpret regions of the genome that exhibit significant changes in chromatin accessibility under different conditions. This process involves several key steps: refining peak calls to fixed-width peaks, defining regions of interest (ROIs), quantifying Tn5 transposase insertion event counts, performing statistical analysis to detect differential signals, and integrating these findings with ChIP-seq annotations for comprehensive biological insights. Refining Peak Calls to Fixed-Width Peaks \u00b6 After the initial peak calling, ASPEN refines these peaks by centering them on their summits and extending them to a uniform width of 500 base pairs (bp). This standardization facilitates consistent downstream analyses and comparisons across different datasets. The approach of extending peak summits by \u00b1250 bp to achieve a fixed width of 500 bp is a common practice in ATAC-seq data analysis, as it focuses on the most accessible regions of the chromatin and reduces variability in peak sizes. Defining Regions of Interest (ROIs) \u00b6 ASPEN processes fixed width peak calls on each replicate across all samples. Subsequently, it generates a union of all identified peaks to create comprehensive regions of interest (ROIs). The pipeline produces ROI.bed and ROI.gtf files for each of the peak callers, which are utilized for quantifying counts using featureCounts. This approach ensures a consistent framework for downstream differential accessibility analysis, enhancing the robustness and interpretability of the results. Quantification of Differential Chromatin Accessibility \u00b6 Once the ROIs are established, ASPEN generates Tn5 nicking sites count matrices: Tn5 Nicking Sites Count Matrix \u00b6 This matrix quantifies the frequency of Tn5 transposase insertion events at each ROI. Reads used by MACS2 and reads coming out of Genrich are used to compute Tn5 sites and counting them. The Tn5 transposase preferentially inserts into accessible regions of the chromatin, and the number of insertion events serves as a proxy for chromatin accessibility. By counting these insertion sites, researchers can accurately infer the openness of chromatin regions under different experimental conditions. Differential Accessibility Analysis with DESeq2 \u00b6 To identify statistically significant differences in chromatin accessibility between conditions, ASPEN employs DESeq2, a widely-used tool for differential analysis of count data. DESeq2 models the count data to detect changes in accessibility, providing robust statistical inferences even with complex experimental designs. By comparing the count matrices across conditions, DESeq2 identifies ROIs with significant differential accessibility, shedding light on regulatory elements that may be functionally relevant to the experimental context. Integration with Gene Annotations \u00b6 To enhance the biological interpretation of differential accessibility results, ASPEN integrates the findings with peak and gene annotations from ChIPSeeker, offering insights into the regulatory landscape of the genome. This integration allows researchers to identify genes located near differentially accessible peaks, which can be crucial for understanding the functional implications of chromatin accessibility changes. By associating these peaks with nearby genes, scientists can infer potential regulatory relationships and gain a deeper understanding of the underlying molecular mechanisms. Reporting \u00b6 ASPEN enhances differential chromatin accessibility analysis by providing an interactive HTML report generated from DESeq2 results, featuring various visualizations. Additionally, it offers a TSV (tabl-delimited) file with integrated gene annotations, compatible with Microsoft Excel, enabling efficient data manipulation and facilitating the identification of genes near regions with altered accessibility. The Excel file is aggregated accross all different contrasts queried in the project.","title":"Overview of ASPEN"},{"location":"overview/#overview-of-aspen","text":"To address these challenges, CCBR developed ASPEN ( A tac S eq P ip E li N e), an automated pipeline tailored for the comprehensive analysis of ATAC-seq data. ASPEN is designed to process paired-end Illumina sequencing data, guiding users from raw data through quality control, alignment, peak calling, and downstream analyses. By integrating a suite of established bioinformatics tools and adhering to best practices, ASPEN ensures robust, reproducible, and high-quality results. For more information on the challenges in ATAC-seq data analysis, refer to the [Challenges in ATAC-seq Data Analysis] section.","title":"Overview of ASPEN"},{"location":"overview/#data-preprocessing","text":"","title":"Data Preprocessing"},{"location":"overview/#adapter-trimming","text":"Utilizes CutAdapt to remove adapter sequences from raw reads, ensuring that subsequent analyses are not confounded by extraneous sequences.","title":"Adapter Trimming"},{"location":"overview/#quality-assessment","text":"Employs FastQC for initial quality checks and MultiQC for aggregated reporting, providing comprehensive insights into data quality and highlighting potential issues such as low-quality bases or GC content biases.","title":"Quality Assessment"},{"location":"overview/#alignment-and-filtering","text":"","title":"Alignment and Filtering"},{"location":"overview/#blacklist-filtering","text":"Removes reads aligning to known blacklisted regions and mitochondria, reducing potential biases in peak detection and ensuring that analyses focus on biologically relevant regions.","title":"Blacklist Filtering"},{"location":"overview/#read-alignment","text":"Aligns reads to the reference genome using Bowtie2, generating multiple output files, including qsorted.bam / tagAlign.gz for peak calling and dedup.bam for downstream analyses.","title":"Read Alignment"},{"location":"overview/#peak-calling-and-annotation","text":"","title":"Peak Calling and Annotation"},{"location":"overview/#peak-detection","text":"Implements MACS2 and Genrich to identify regions of open chromatin, accommodating both narrow and broad peak detection to capture a wide range of regulatory elements. Default MACS2 are selected from ENCODE. Peak calling uses lenient q-value setting and a q-value filter is then applied on the .narrowPeak file.","title":"Peak Detection"},{"location":"overview/#consensus-peaks","text":"For datasets with multiple replicates, ASPEN generates consensus peak sets based on simple overlaps between replicates and keeping peaks represented in >= 50% of replicates. Thus enhancing the reliability and reproducibility of detected regions by focusing on peaks consistently observed across replicates.","title":"Consensus Peaks"},{"location":"overview/#peak-annotation","text":"Utilizes ChIPseeker to annotate peaks, providing context regarding their genomic locations and potential regulatory roles, such as associations with promoters, enhancers, or gene bodies.","title":"Peak Annotation"},{"location":"overview/#quality-control-metrics","text":"","title":"Quality Control Metrics"},{"location":"overview/#fragment-length-distribution","text":"Custom scripts are utilized to analyze insert size to assess nucleosome positioning and sample quality, with characteristic patterns indicating the presence of nucleosome-free regions and mono- or di-nucleosomes.","title":"Fragment Length Distribution"},{"location":"overview/#library-complexity","text":"Estimates complexity using Preseq, aiding in the evaluation of sequencing depth sufficiency and potential PCR biases.","title":"Library Complexity"},{"location":"overview/#transcription-start-site-tss-enrichment","text":"Calculates TSS enrichment scores, serving as indicators of data quality by measuring the accumulation of reads around transcription start sites, a hallmark of open chromatin.","title":"Transcription Start Site (TSS) Enrichment"},{"location":"overview/#fraction-of-reads-in-peaks-frip","text":"Determines the proportion of reads within called peaks, reflecting the signal-to-noise ratio and overall quality of the dataset. Fractions if reads in Promoters, Enhancers and DHS (DNase Hyper Sensitivity) regions are also computed.","title":"Fraction of Reads in Peaks (FRiP)"},{"location":"overview/#motif-enrichment-analysis","text":"","title":"Motif Enrichment Analysis"},{"location":"overview/#homer-and-ame","text":"Conducts motif enrichment analyses to identify potential transcription factor binding sites within accessible regions, offering insights into regulatory mechanisms and facilitating the discovery of key drivers of gene expression.","title":"HOMER and AME"},{"location":"overview/#comprehensive-reporting","text":"","title":"Comprehensive Reporting"},{"location":"overview/#multiqc-integration","text":"Generates an extensive HTML report consolidating all QC metrics and analysis results, facilitating easy interpretation, visualization, and sharing of findings.","title":"MultiQC Integration"},{"location":"overview/#differential-accessiblity-analyses","text":"In addition to its core functionalities, ASPEN offers advanced capabilities for differential accessibility analysis, enabling researchers to identify and interpret regions of the genome that exhibit significant changes in chromatin accessibility under different conditions. This process involves several key steps: refining peak calls to fixed-width peaks, defining regions of interest (ROIs), quantifying Tn5 transposase insertion event counts, performing statistical analysis to detect differential signals, and integrating these findings with ChIP-seq annotations for comprehensive biological insights.","title":"Differential Accessiblity Analyses"},{"location":"overview/#refining-peak-calls-to-fixed-width-peaks","text":"After the initial peak calling, ASPEN refines these peaks by centering them on their summits and extending them to a uniform width of 500 base pairs (bp). This standardization facilitates consistent downstream analyses and comparisons across different datasets. The approach of extending peak summits by \u00b1250 bp to achieve a fixed width of 500 bp is a common practice in ATAC-seq data analysis, as it focuses on the most accessible regions of the chromatin and reduces variability in peak sizes.","title":"Refining Peak Calls to Fixed-Width Peaks"},{"location":"overview/#defining-regions-of-interest-rois","text":"ASPEN processes fixed width peak calls on each replicate across all samples. Subsequently, it generates a union of all identified peaks to create comprehensive regions of interest (ROIs). The pipeline produces ROI.bed and ROI.gtf files for each of the peak callers, which are utilized for quantifying counts using featureCounts. This approach ensures a consistent framework for downstream differential accessibility analysis, enhancing the robustness and interpretability of the results.","title":"Defining Regions of Interest (ROIs)"},{"location":"overview/#quantification-of-differential-chromatin-accessibility","text":"Once the ROIs are established, ASPEN generates Tn5 nicking sites count matrices:","title":"Quantification of Differential Chromatin Accessibility"},{"location":"overview/#tn5-nicking-sites-count-matrix","text":"This matrix quantifies the frequency of Tn5 transposase insertion events at each ROI. Reads used by MACS2 and reads coming out of Genrich are used to compute Tn5 sites and counting them. The Tn5 transposase preferentially inserts into accessible regions of the chromatin, and the number of insertion events serves as a proxy for chromatin accessibility. By counting these insertion sites, researchers can accurately infer the openness of chromatin regions under different experimental conditions.","title":"Tn5 Nicking Sites Count Matrix"},{"location":"overview/#differential-accessibility-analysis-with-deseq2","text":"To identify statistically significant differences in chromatin accessibility between conditions, ASPEN employs DESeq2, a widely-used tool for differential analysis of count data. DESeq2 models the count data to detect changes in accessibility, providing robust statistical inferences even with complex experimental designs. By comparing the count matrices across conditions, DESeq2 identifies ROIs with significant differential accessibility, shedding light on regulatory elements that may be functionally relevant to the experimental context.","title":"Differential Accessibility Analysis with DESeq2"},{"location":"overview/#integration-with-gene-annotations","text":"To enhance the biological interpretation of differential accessibility results, ASPEN integrates the findings with peak and gene annotations from ChIPSeeker, offering insights into the regulatory landscape of the genome. This integration allows researchers to identify genes located near differentially accessible peaks, which can be crucial for understanding the functional implications of chromatin accessibility changes. By associating these peaks with nearby genes, scientists can infer potential regulatory relationships and gain a deeper understanding of the underlying molecular mechanisms.","title":"Integration with Gene Annotations"},{"location":"overview/#reporting","text":"ASPEN enhances differential chromatin accessibility analysis by providing an interactive HTML report generated from DESeq2 results, featuring various visualizations. Additionally, it offers a TSV (tabl-delimited) file with integrated gene annotations, compatible with Microsoft Excel, enabling efficient data manipulation and facilitating the identification of genes near regions with altered accessibility. The Excel file is aggregated accross all different contrasts queried in the project.","title":"Reporting"}]}