{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#aspen","title":"ASPEN","text":"<p>Atac Seq PipEliNe</p> <p></p>"},{"location":"#table-of-contents","title":"Table of Contents","text":"<ul> <li>ASPEN</li> <li>1. Outline</li> <li>2. Runtime details<ul> <li>2.1 Load Module On Biowulf</li> <li>2.2 Create Sample Manifest</li> <li>2.3 Run Pipeline</li> </ul> </li> <li>3. Genomes</li> <li>4. Disclaimer</li> <li>5. Help</li> </ul>"},{"location":"#1-outline","title":"1. Outline","text":"<p>ASPEN or Atac Seq PipEliNe is CCBR's pipeline to calls peaks for ATAC-Seq datasets. It currently accepts paired-end Illumina data and calls peak using MACS2 and Genrich peak callers. Below is a brief outline of the steps performed by the pipeline:</p> <ul> <li>Trim PE reads with CutAdapt</li> <li>Remove reads aligning to known blacklisted regions, if provided</li> <li>Align reads provided genome using bowtie2. This step generates multiple output files:</li> <li><code>tagAlign.gz</code>, which is a BED6 format file mainly required for MACS2 peak calling</li> <li><code>dedup.bam</code>, deduplicated BAM format file which may be required for downstream processing (eg. TOBIAS)</li> <li><code>qsorted.bam</code>, query sorted BAM file for Genrich peak calling</li> <li>Pre-peakcalling QC metrics:</li> <li>FastQC is run pre- and post-trimming</li> <li>Fragment length distribution is calculated using custom scripts</li> <li>Preseq is run to estimate library complexity</li> <li>Post-peakcalling QC metrics:</li> <li>TSS distributions are calculated for each replicate</li> <li>FRiP (Fraction of Reads in Peaks) is calculated for each replicate</li> <li>FRiPextra calculations are performed if fripextra config files are supplied<ul> <li>Fraction of reads in DHS regions</li> <li>Fraction of reads in promoter regions</li> <li>Fraction of reads in enhancer regions</li> </ul> </li> <li>Peak calling: Peaks (NarrowPeak format) are called using MACS2 and Genrich. If multiple replicates exist per sample, consensus peaks are called (BED format).</li> <li>Peak annotation: ChIPseeker is used to annotate peaks if the genome is hg38/hg19/mm10</li> <li>Motif enrichment: Motif Enrichment is calculated using HOMER and AME (MEME suite)</li> <li>Report: MultiQC is used to generate a customized final HTML report</li> </ul>"},{"location":"#2-runtime-details","title":"2. Runtime details","text":""},{"location":"#21-load-module-on-biowulf","title":"2.1 Load module on BIOWULF","text":"<p>To clone the repo run:</p> <pre><code>% module load ccbrpipeliner\n</code></pre> <p>This will add <code>aspen</code> to your PATH environmental variable.</p> <p>NOTE: If not running on BIOWULF, please ensure that the required tools like snakemake, python and singularity are in PATH.</p>"},{"location":"#22-create-sample-manifest","title":"2.2 Create Sample Manifest","text":"<p>Once the data is stored on biowulf, sample manifest TSV (<code>samples.tsv</code>) can be created to have the following columns:</p> <ol> <li> <p>replicateName</p> </li> <li> <p>sampleName: Multiple replicates can have the same sampleName</p> </li> <li> <p>path_to_R1_fastq: absolute path is preferred</p> </li> <li> <p>path_to_R2_fastq: Required! Pipeline currently only supports paired-end data</p> </li> </ol> <p>Note that:</p> <ul> <li>symlinks are created for R1 and R2 files from the sample manifest in the results folder. These symlinks have the filenames \\&lt;replicateName&gt;.R1.fastq.gz and \\&lt;replicateName&gt;.R2.fastq.gz, respectively. Thus, original filenames do not matter and original files do not need to be renamed.</li> <li>replicateName is used as prefix for individual peak calls</li> <li>sampleName is used as prefix for consensus peak calls</li> </ul> <p>NOTE: Optionally, if running differential ATAC please also provide <code>contrasts.tsv</code> in the output folder after running <code>init</code>. This is a simple tab-delimited text file with 2 columns (Group1 and Group2) without any headers.</p>"},{"location":"#23-run-pipeline","title":"2.3 Run Pipeline","text":"<p>To get more information about how to run the pipeline simply <code>cd</code> to the above <code>CCBR_ATACseq</code> folder and run</p> <pre><code>% aspen --help\n##########################################################################################\n\nWelcome to\n____ ____ ___  ____ _  _\n|__| [__  |__] |___ |\\ |\n|  | ___] |    |___ | \\|    v1.0.0\n\nA_TAC_S_eq A_nalysis P_ip_E_li_N_e\n\n##########################################################################################\n\nThis pipeline was built by CCBR (https://bioinformatics.ccr.cancer.gov/ccbr)\nPlease contact Vishal Koparde for comments/questions (vishal.koparde@nih.gov)\n\n##########################################################################################\n\nHere is a list of genome supported by aspen:\n\n  * hg19          [Human]\n* hg38          [Human]\n* mm10          [Mouse]\n* mmul10        [Macaca mulatta(Rhesus monkey) or rheMac10]\n* bosTau9       [Bos taurus(cattle)]\n\naspen calls peaks using the following tools:\n\n * MACS2\n * Genrich        [RECOMMENDED FOR USE]\n\nUSAGE:\n  bash ./aspen -w/--workdir=&lt;WORKDIR&gt; -m/--runmode=&lt;RUNMODE&gt;\n\nRequired Arguments:\n1.  WORKDIR     : [Type: String]: Absolute or relative path to the output folder with write permissions.\n\n2.  RUNMODE     : [Type: String] Valid options:\n    * init      : initialize workdir\n    * dryrun    : dry run snakemake to generate DAG\n    * run       : run with slurm\n    * runlocal  : run without submitting to sbatch\n    ADVANCED RUNMODES (use with caution!!)\n* unlock    : unlock WORKDIR if locked by snakemake NEVER UNLOCK WORKDIR WHERE PIPELINE IS CURRENTLY RUNNING!\n    * reconfig  : recreate config file in WORKDIR (debugging option) EDITS TO config.yaml WILL BE LOST!\n    * reset     : DELETE workdir dir and re-init it (debugging option) EDITS TO ALL FILES IN WORKDIR WILL BE LOST!\n    * printbinds: print singularity binds (paths)\n* local     : same as runlocal\n\nOptional Arguments:\n\n--help|-h       : print this help\n--genome|-g     : genome eg. hg38\n--manifest|-s   : absolute path to samples.tsv. This will be copied to output folder                    (--runmode=init only)\n--useenvmod|-e  : use \"--use-enmodules\" option while running Snakemake. This is for using modules on HPC instead of containers(default).\n--singcache|-c  : singularity cache directory. Default is `/data/${USER}/.singularity` if available, or falls back to `${WORKDIR}/.singularity`.\n\n\nExample commands:\n  bash ./aspen -w=/my/output/folder -m=init\n  bash ./aspen -w=/my/output/folder -m=dryrun\n  bash ./aspen -w=/my/output/folder -m=run\n  bash ./aspen -w=/my/output/folder -m=run -c /data/${USER}/.singularity\n\n##########################################################################################\n\nVersionInfo:\n  python          : python/3.10\n  snakemake       : snakemake\n  pipeline_home   : /gpfs/gsfs10/users/CCBR_Pipeliner/Pipelines/ASPEN/dev\n  git commit/tag  : 51cb3aee2142ce1226acca97e1e662d54c881a13    v1.0.0-2-g51cb3ae\n  aspen_version   : v1.0.0\n\n##########################################################################################\n</code></pre> <p><code>aspen</code> is a Biowulf and FRCE specific wrapper script to the pipeline. Essentially, to run the pipeline the user has to follow 3 steps:</p> <ol> <li>Initialize the output folder:</li> </ol> <p>This can be done using the following command:</p> <pre><code>% aspen -m=init -w=&lt;path_to_output_folder&gt;\n</code></pre> <p>The above command will create <code>config.yaml</code> and <code>samples.tsv</code> in the output folder. Please edit these as per your requirements. You can replace the <code>samples.tsv</code> file in the output folder with the sample manifest created in the previous step outlined above. <code>contrasts.tsv</code> should also be included if running differential ATAC.</p> <ol> <li>Dryrun:</li> </ol> <p>To dry-run the pipeline, you can run the following command after initializing the output folder:</p> <pre><code>% aspen -m=dryrun -w=&lt;path_to_output_folder&gt;\n</code></pre> <p>This should list out the chain of jobs (DAG) that will be submitted to the job scheduler.</p> <ol> <li>RUN!!:</li> </ol> <p>If the dry-run looks as expected, then you can submit the job using:</p> <pre><code>% aspen -m=run -w=&lt;path_to_output_folder&gt;\n</code></pre> <p>This will submit one master job to slurm, which will in turn keep managing the entire pipeline and submit/monitor jobs to the job scheduler as and when required.</p>"},{"location":"#3-genomes","title":"3. Genomes","text":"<p>ASPEN supports the following genome versions:</p> Genome Version Organism hg38 Human hg19 Human mm10 Mouse mmul10 Macaca mulatta(Rhesus monkey) or rheMac10 bosTau9 Bos taurus(cattle)"},{"location":"#4-disclaimer","title":"4. Disclaimer","text":"<p>This snakemake pipeline is built to run on Biowulf and FRCE. But, as it uses containers for all intermediate steps, the pipeline can be executed on any HPC with minimal edits to the config file.</p>"},{"location":"#5-help","title":"5. Help","text":"<p>For comments/suggestions/advice please reach out to Vishal Koparde or CCBR_Pipeliner. You can also open a new issue here.</p> <p> Back to Top </p>"},{"location":"changelog/","title":"Changelog","text":""},{"location":"changelog/#aspen-development-version","title":"ASPEN development version","text":"<ul> <li>ASPEN is now archived on Zenodo, you can cite it with the DOI 10.5281/zenodo.13755867. (#42, @kelly-sovacool)</li> </ul>"},{"location":"changelog/#aspen-102","title":"ASPEN 1.0.2","text":"<ul> <li>Set the singularity cache dir if <code>--singcache</code> is not provided. (#37, @kelly-sovacool)</li> <li>ASPEN now has a documentation website: https://ccbr.github.io/ASPEN</li> </ul>"},{"location":"changelog/#aspen-101","title":"ASPEN 1.0.1","text":"<ul> <li>differential ATAC updated</li> <li>documentation updated</li> </ul>"},{"location":"changelog/#aspen-100","title":"ASPEN 1.0.0","text":"<ul> <li>completely dockerized</li> <li>differential ATAC</li> </ul>"},{"location":"changelog/#aspen-061","title":"ASPEN 0.6.1","text":"<ul> <li>correction to fqscreen cattle path</li> </ul>"},{"location":"changelog/#aspen-06","title":"ASPEN 0.6","text":"<ul> <li>support for mmul10 (Macaca) and bosTau9 (cattle) genomes</li> <li>created resource files: indexes, promoter files, tss files etc.</li> <li>Added Macaca and Cattle to fastqscreen indexes</li> <li>support increased from 4 replicate to 6 replicates</li> <li>macs and genrich fixed width peaks generation rule added</li> <li>docker updated to v10 (genome support and tidyverse added)</li> </ul>"},{"location":"changelog/#aspen-053","title":"ASPEN 0.5.3","text":"<ul> <li>Includes reference files for mmul10</li> </ul>"},{"location":"changelog/#aspen-052","title":"ASPEN 0.5.2","text":"<ul> <li>atac_assign_multimappers.py now getting query sorted input</li> <li>dryrun log saved in workdir</li> <li>local (workdir) scriptsdir used</li> </ul>"},{"location":"changelog/#aspen-051","title":"ASPEN 0.5.1","text":"<ul> <li>typo fix in main wrapper script</li> </ul>"},{"location":"changelog/#aspen-05","title":"ASPEN 0.5","text":"<ul> <li>fastqscreen added</li> <li>minor bug fixes</li> </ul>"},{"location":"changelog/#aspen-041","title":"ASPEN 0.4.1","text":"<ul> <li>Bug fixes</li> <li>minor updates</li> </ul>"},{"location":"changelog/#aspen-04","title":"ASPEN 0.4","text":"<ul> <li>Multiqc edits</li> <li>README updates</li> </ul>"},{"location":"changelog/#aspen-03","title":"ASPEN 0.3","text":"<ul> <li>FRiP calculations added</li> </ul>"},{"location":"changelog/#aspen-02","title":"ASPEN 0.2","text":"<ul> <li>Peak motif enrichment with homer/meme</li> <li>Peak replicate/sample/peakcaller PCA comparisons after bedtools jaccard pairwise calculations</li> </ul>"},{"location":"changelog/#aspen-01","title":"ASPEN 0.1","text":"<ul> <li>first working version</li> <li>calls peaks with macs2/genrich</li> <li>annotates peaks with chipseeker (human and mouse support)</li> </ul>"},{"location":"contributing/","title":"Contributing to ASPEN","text":""},{"location":"contributing/#proposing-changes-with-issues","title":"Proposing changes with issues","text":"<p>If you want to make a change, it's a good idea to first open an issue and make sure someone from the team agrees that it\u2019s needed.</p> <p>If you've decided to work on an issue, assign yourself to the issue so others will know you're working on it.</p>"},{"location":"contributing/#pull-request-process","title":"Pull request process","text":"<p>We use GitHub Flow as our collaboration process. Follow the steps below for detailed instructions on contributing changes to ASPEN.</p> <p></p>"},{"location":"contributing/#clone-the-repo","title":"Clone the repo","text":"<p>If you are a member of CCBR, you can clone this repository to your computer or development environment. Otherwise, you will first need to fork the repo and clone your fork. You only need to do this step once.</p> <pre><code>git clone https://github.com/CCBR/ASPEN\n</code></pre> <p>Cloning into 'ASPEN'...  remote: Enumerating objects: 1136, done.  remote: Counting objects: 100% (463/463), done.  remote: Compressing objects: 100% (357/357), done.  remote: Total 1136 (delta 149), reused 332 (delta 103), pack-reused 673  Receiving objects: 100% (1136/1136), 11.01 MiB | 9.76 MiB/s, done.  Resolving deltas: 100% (530/530), done. </p> <pre><code>cd ASPEN\n</code></pre>"},{"location":"contributing/#if-this-is-your-first-time-cloning-the-repo-you-may-need-to-install-dependencies","title":"If this is your first time cloning the repo, you may need to install dependencies","text":"<ul> <li> <p>Install snakemake and singularity or docker if needed (biowulf already has these available as modules).</p> </li> <li> <p>Install the python dependencies with pip</p> </li> </ul> <pre><code>pip install .\n</code></pre> <p>If you're developing on biowulf, you can use our shared conda environment which already has these dependencies installed</p> <pre><code>. \"/data/CCBR_Pipeliner/db/PipeDB/Conda/etc/profile.d/conda.sh\"\nconda activate py311\n</code></pre> <ul> <li>Install <code>pre-commit</code> if you don't already   have it. Then from the repo's root directory, run</li> </ul> <pre><code>pre-commit install\n</code></pre> <p>This will install the repo's pre-commit hooks.   You'll only need to do this step the first time you clone the repo.</p>"},{"location":"contributing/#create-a-branch","title":"Create a branch","text":"<p>Create a Git branch for your pull request (PR). Give the branch a descriptive name for the changes you will make, such as <code>iss-10</code> if it is for a specific issue.</p> <pre><code># create a new branch and switch to it\ngit branch iss-10\ngit switch iss-10\n</code></pre> <p>Switched to a new branch 'iss-10'</p>"},{"location":"contributing/#make-your-changes","title":"Make your changes","text":"<p>Edit the code, write and run tests, and update the documentation as needed.</p>"},{"location":"contributing/#test","title":"test","text":"<p>Changes to the python package code will also need unit tests to demonstrate that the changes work as intended. We write unit tests with pytest and store them in the <code>tests/</code> subdirectory. Run the tests with <code>python -m pytest</code>.</p> <p>If you change the workflow, please run the workflow with the test profile and make sure your new feature or bug fix works as intended.</p>"},{"location":"contributing/#document","title":"document","text":"<p>If you have added a new feature or changed the API of an existing feature, you will likely need to update the documentation in <code>docs/</code>.</p>"},{"location":"contributing/#commit-and-push-your-changes","title":"Commit and push your changes","text":"<p>If you're not sure how often you should commit or what your commits should consist of, we recommend following the \"atomic commits\" principle where each commit contains one new feature, fix, or task. Learn more about atomic commits here: https://www.freshconsulting.com/insights/blog/atomic-commits/</p> <p>First, add the files that you changed to the staging area:</p> <pre><code>git add path/to/changed/files/\n</code></pre> <p>Then make the commit. Your commit message should follow the Conventional Commits specification. Briefly, each commit should start with one of the approved types such as <code>feat</code>, <code>fix</code>, <code>docs</code>, etc. followed by a description of the commit. Take a look at the Conventional Commits specification for more detailed information about how to write commit messages.</p> <pre><code>git commit -m 'feat: create function for awesome feature'\n</code></pre> <p>pre-commit will enforce that your commit message and the code changes are styled correctly and will attempt to make corrections if needed.</p> <p>Check for added large files..............................................Passed  Fix End of Files.........................................................Passed  Trim Trailing Whitespace.................................................Failed </p> <ul> <li>hook id: trailing-whitespace </li> <li>exit code: 1 </li> <li>files were modified by this hook  &gt;    Fixing path/to/changed/files/file.txt  &gt;    codespell................................................................Passed    style-files..........................................(no files to check)Skipped    readme-rmd-rendered..................................(no files to check)Skipped    use-tidy-description.................................(no files to check)Skipped </li> </ul> <p>In the example above, one of the hooks modified a file in the proposed commit, so the pre-commit check failed. You can run <code>git diff</code> to see the changes that pre-commit made and <code>git status</code> to see which files were modified. To proceed with the commit, re-add the modified file(s) and re-run the commit command:</p> <pre><code>git add path/to/changed/files/file.txt\ngit commit -m 'feat: create function for awesome feature'\n</code></pre> <p>This time, all the hooks either passed or were skipped (e.g. hooks that only run on R code will not run if no R files were committed). When the pre-commit check is successful, the usual commit success message will appear after the pre-commit messages showing that the commit was created.</p> <p>Check for added large files..............................................Passed  Fix End of Files.........................................................Passed  Trim Trailing Whitespace.................................................Passed  codespell................................................................Passed  style-files..........................................(no files to check)Skipped  readme-rmd-rendered..................................(no files to check)Skipped  use-tidy-description.................................(no files to check)Skipped  Conventional Commit......................................................Passed  &gt; [iss-10 9ff256e] feat: create function for awesome feature  1 file changed, 22 insertions(+), 3 deletions(-) </p> <p>Finally, push your changes to GitHub:</p> <pre><code>git push\n</code></pre> <p>If this is the first time you are pushing this branch, you may have to explicitly set the upstream branch:</p> <pre><code>git push --set-upstream origin iss-10\n</code></pre> <p>Enumerating objects: 7, done.  Counting objects: 100% (7/7), done.  Delta compression using up to 10 threads  Compressing objects: 100% (4/4), done.  Writing objects: 100% (4/4), 648 bytes | 648.00 KiB/s, done.  Total 4 (delta 3), reused 0 (delta 0), pack-reused 0  remote: Resolving deltas: 100% (3/3), completed with 3 local objects.  remote:  remote: Create a pull request for 'iss-10' on GitHub by visiting:  remote: https://github.com/CCBR/ASPEN/pull/new/iss-10  remote:  To https://github.com/CCBR/ASPEN  &gt;  &gt; [new branch] iss-10 -&gt; iss-10  branch 'iss-10' set up to track 'origin/iss-10'. </p> <p>We recommend pushing your commits often so they will be backed up on GitHub. You can view the files in your branch on GitHub at <code>https://github.com/CCBR/ASPEN/tree/&lt;your-branch-name&gt;</code> (replace <code>&lt;your-branch-name&gt;</code> with the actual name of your branch).</p>"},{"location":"contributing/#create-the-pr","title":"Create the PR","text":"<p>Once your branch is ready, create a PR on GitHub: https://github.com/CCBR/ASPEN/pull/new/</p> <p>Select the branch you just pushed:</p> <p></p> <p>Edit the PR title and description. The title should briefly describe the change. Follow the comments in the template to fill out the body of the PR, and you can delete the comments (everything between <code>&lt;!--</code> and <code>--&gt;</code>) as you go. Be sure to fill out the checklist, checking off items as you complete them or striking through any irrelevant items. When you're ready, click 'Create pull request' to open it.</p> <p></p> <p>Optionally, you can mark the PR as a draft if you're not yet ready for it to be reviewed, then change it later when you're ready.</p>"},{"location":"contributing/#wait-for-a-maintainer-to-review-your-pr","title":"Wait for a maintainer to review your PR","text":"<p>We will do our best to follow the tidyverse code review principles: https://code-review.tidyverse.org/. The reviewer may suggest that you make changes before accepting your PR in order to improve the code quality or style. If that's the case, continue to make changes in your branch and push them to GitHub, and they will appear in the PR.</p> <p>Once the PR is approved, the maintainer will merge it and the issue(s) the PR links will close automatically. Congratulations and thank you for your contribution!</p>"},{"location":"contributing/#after-your-pr-has-been-merged","title":"After your PR has been merged","text":"<p>After your PR has been merged, update your local clone of the repo by switching to the main branch and pulling the latest changes:</p> <pre><code>git checkout main\ngit pull\n</code></pre> <p>It's a good idea to run <code>git pull</code> before creating a new branch so it will start from the most recent commits in main.</p>"},{"location":"contributing/#helpful-links-for-more-information","title":"Helpful links for more information","text":"<ul> <li>GitHub Flow</li> <li>semantic versioning guidelines</li> <li>changelog guidelines</li> <li>tidyverse code review principles</li> <li>reproducible examples</li> <li>nf-core extensions for VS Code</li> </ul>"},{"location":"log/","title":"Log","text":""},{"location":"log/#creation-of-test-dataset","title":"Creation of test dataset","text":"<p>Using the D4_Meso_iCre_Dox and iCre_D0 samples from the ccbr872 mouse dataset:</p> <ul> <li>Select 2 replicates for each group .. total samples = 4</li> <li>extract readids from the chr19:10000000-20000000 region using:  <code>% samtools view /data/CCBR/projects/ccbr872/atacseq/test/bam/iCre_D0_1.dedup.bam chr19:10000000-20000000|awk -F\"\\t\" '{print $1}' |sort|uniq &gt; iCre_D0_1.chr19.readids &amp; % samtools view /data/CCBR/projects/ccbr872/atacseq/test/bam/iCre_D0_2.dedup.bam chr19:10000000-20000000|awk -F\"\\t\" '{print $1}' |sort|uniq &gt; iCre_D0_2.chr19.readids &amp; % samtools view /data/CCBR/projects/ccbr872/atacseq/test/bam/D4_Meso_iCre_Dox_1.dedup.bam chr19:10000000-20000000|awk -F\"\\t\" '{print $1}' |sort|uniq &gt; D4_Meso_iCre_Dox_1.chr19.readids &amp; % samtools view /data/CCBR/projects/ccbr872/atacseq/test/bam/D4_Meso_iCre_Dox_2.dedup.bam chr19:10000000-20000000|awk -F\"\\t\" '{print $1}' |sort|uniq &gt; D4_Meso_iCre_Dox_2.chr19.readids &amp; <pre><code> * create subsampled fastq files using these readids:\n ```\n% cd /data/CCBR/rawdata/ccbr872/ccbr872_atacseq/fastq\n% python /data/kopardevn/GitRepos/Tools/scripts/filter_fastq_by_readids_highmem_pe.py --infq iCre_D0_1.R1.fastq.gz --infq2 iCre_D0_1.R2.fastq.gz --outfq iCre_D0_1.subset.R1.fastq.gz --outfq2 iCre_D0_1.subset.R2.fastq.gz --readids iCre_D0_1.chr19.readids\n% python /data/kopardevn/GitRepos/Tools/scripts/filter_fastq_by_readids_highmem_pe.py --infq iCre_D0_2.R1.fastq.gz --infq2 iCre_D0_2.R2.fastq.gz --outfq iCre_D0_2.subset.R1.fastq.gz --outfq2 iCre_D0_2.subset.R2.fastq.gz --readids iCre_D0_2.chr19.readids\n% python /data/kopardevn/GitRepos/Tools/scripts/filter_fastq_by_readids_highmem_pe.py --infq D4_Meso_iCre_Dox_1.R1.fastq.gz --infq2 D4_Meso_iCre_Dox_1.R2.fastq.gz --outfq D4_Meso_iCre_Dox_1.subset.R1.fastq.gz --outfq2 D4_Meso_iCre_Dox_1.subset.R2.fastq.gz --readids D4_Meso_iCre_Dox_1.chr19.readids\n% python /data/kopardevn/GitRepos/Tools/scripts/filter_fastq_by_readids_highmem_pe.py --infq D4_Meso_iCre_Dox_2.R1.fastq.gz --infq2 D4_Meso_iCre_Dox_2.R2.fastq.gz --outfq D4_Meso_iCre_Dox_2.subset.R1.fastq.gz --outfq2 D4_Meso_iCre_Dox_2.subset.R2.fastq.gz --readids D4_Meso_iCre_Dox_2.chr19.readids\n ```\n\nNow, the **samples.tsv** will look something like this:\n</code></pre> sampleName  path_to_R1_fastq    path_to_R2_fastq D4_Meso_iCre_Dox_1  /data/CCBR/rawdata/ccbr872/ccbr872_atacseq/fastq/D4_Meso_iCre_Dox_1.subset.R1.fastq.paired.fq.gz    /data/CCBR/rawdata/ccbr872/ccbr872_atacseq/fastq/D4_Meso_iCre_Dox_1.subset.R2.fastq.pai red.fq.gz D4_Meso_iCre_Dox_2  /data/CCBR/rawdata/ccbr872/ccbr872_atacseq/fastq/D4_Meso_iCre_Dox_2.subset.R1.fastq.paired.fq.gz    /data/CCBR/rawdata/ccbr872/ccbr872_atacseq/fastq/D4_Meso_iCre_Dox_2.subset.R2.fastq.pai red.fq.gz iCre_D0_1   /data/CCBR/rawdata/ccbr872/ccbr872_atacseq/fastq/iCre_D0_1.subset.R1.fastq.paired.fq.gz /data/CCBR/rawdata/ccbr872/ccbr872_atacseq/fastq/iCre_D0_1.subset.R2.fastq.paired.fq.gz iCre_D0_2   /data/CCBR/rawdata/ccbr872/ccbr872_atacseq/fastq/iCre_D0_2.subset.R1.fastq.paired.fq.gz /data/CCBR/rawdata/ccbr872/ccbr872_atacseq/fastq/iCre_D0_2.subset.R2.fastq.paired.fq.gz</code></li> </ul>"}]}